## Dive into MySQL

### index

Indexes are the most important means for improving query performance in relational databases. An index in a relational database is like the catalog of a book. We can imagine that if we want to find out a certain knowledge point from a book, but this book has no catalog, what a terrible thing it will be! We estimate that we have to go through it one by one to determine where this knowledge point is. Although creating an index will bring storage space overhead, just like the content of a book will occupy a part of the space, but the reduction in query time after sacrificing space is also very significant.

Columns of all data types in a MySQL database can be indexed. For the MySQL 8.0 version of the InnoDB storage engine, it supports three types of indexes, namely B+ tree indexes, full-text indexes, and R-tree indexes. Here, we only introduce the most widely used B+ tree indexes. The reason for using a B+ tree is very simple, because it is currently the most efficient data structure for disk-based storage and sorting of massive data. A B+ tree is a [balanced tree](https://zh.wikipedia.org/zh-cn/%E5%B9%B3%E8%A1%A1%E6%A0%91), the height of the tree is usually 3 Or 4, but it can save data from millions to billions, and querying a piece of data from these data requires only 3 or 4 I/O operations.

A B+ tree consists of a root node, intermediate nodes and leaf nodes, where the leaf nodes are used to store sorted data. Since the records are sorted on the index, binary search can be used when searching for data in a leaf node, which is very efficient. When there is very little data, the B+ tree has only one root node, and the data is stored on the root node. With more and more records, the B+ tree will split, and the root node no longer saves data, but provides a pointer to access the next layer of nodes, helping to quickly determine which leaf node the data is on.

When creating a two-dimensional table, we usually specify a primary key column for the table, and an index is created by default on the primary key column. For the MySQL InnoDB storage engine, because it uses the data storage structure of an index-organized table, the primary key The index is the data of the entire table, and this kind of index is also called **clustered index** (clustered index). Obviously, a table can only have one clustered index, otherwise the data of the table will be saved many times. The indexes we create ourselves are all secondary indexes, more commonly known as non-clustered indexes. Through our custom non-clustered index, only the primary key of the record can be located. When obtaining data, it may be necessary to query through the clustered index on the primary key. This phenomenon is called "return table". Therefore, retrieving data through a non-clustered index is usually faster than Retrieving data using a clustered index is slower.

Next, we will use a simple example to illustrate the meaning of indexing. For example, we need to find students based on their names. This scenario should be often encountered in actual development, which is the same as finding products by product names. We can use MySQL's `explain` keyword to view the SQL execution plan (the specific steps that the database executes the SQL statement).

````SQL
explain select * from tb_student where stuname='Lin Zhennan'\G
````

````
**************************** 1. row ******************** ******
           id: 1
  select_type: SIMPLE
        table: tb_student
   partitions: NULL
         type: ALL
possible_keys: NULL
          key: NULL
      key_len: NULL
          ref: NULL
         rows: 11
     filtered: 10.00
        Extra: Using where
1 row in set, 1 warning (0.00 sec)
````

In the above SQL execution plan, there are several items worth our attention:

1. `select_type`: The type of query.
    - `SIMPLE`: Simple SELECT, without using UNION operations or subqueries.
    - `PRIMARY`: If the query contains subqueries, the outermost SELECT is marked as PRIMARY.
    - `UNION`: The second or subsequent SELECT statement in a UNION operation.
    - `SUBQUERY`: The first SELECT in a subquery.
    - `DERIVED`: SELECT subqueries for derived tables.
2. `table`: query the corresponding table.
3. `type`: The way MySQL finds rows that meet the conditions in the table, also known as the access type, including: `ALL` (full table scan), `index` (index full scan, only traverse the index tree), ` range` (index range scan), `ref` (non-unique index scan), `eq_ref` (unique index scan), `const` / `system` (const level query), `NULL` (no table or index access required ). Of all the access types, ALL is obviously the worst performing, and it represents a full table scan that scans every row in the table to find a matching row.
4. `possible_keys`: MySQL can select indexes, but **may not use**.
5. `key`: The index actually used by MySQL, if it is `NULL`, it means that no index is used.
6. `key_len`: The length of the index used, the shorter the length, the better without affecting the query.
7. `rows`: The number of rows that need to be scanned to execute the query, which is an **estimated value**.
8. `extra`: extra information about the query.
    - `Using filesort`: MySQL cannot use the index to complete the sorting operation.
    - `Using index`: Only use index information without further table lookup to get more information.
    - `Using temporary`: MySQL needs to use temporary tables to store result sets, which are often used for grouping and sorting.
    - `Impossible where`: The `where` clause results in no rows matching the condition.
    - `Distinct`: MySQL stops searching for more rows for the current row combination after finding the first matching row.
    - `Using where`: The query column is not covered by the index, and the filter condition is not the leading column of the index.

As can be seen from the above execution plan, when we query students by student name, we actually perform a full table scan. It goes without saying that the performance of this query must be very bad, especially when there are many rows in the table. If we need to frequently query students by their names, we should create an index on the column corresponding to the student's name to speed up the query through the index.

````SQL
create index idx_student_name on tb_student(stuname);
````

View the execution plan corresponding to the SQL just now.

````SQL
explain select * from tb_student where stuname='Lin Zhennan'\G
````

````
**************************** 1. row ******************** ******
           id: 1
  select_type: SIMPLE
        table: tb_student
   partitions: NULL
         type: ref
possible_keys: idx_student_name
          key: idx_student_name
      key_len: 62
          ref: const
         rows: 1
     filtered: 100.00
        Extra: NULL
1 row in set, 1 warning (0.00 sec)
````

It can be noticed that after creating an index on the student's name, the query just now is not a full table scan but an index-based query, and the scanned row is only one row, which obviously greatly improves the performance of the query. MySQL also allows to create a prefix index, that is to create an index on the first N characters of the index field, which can reduce the space occupied by the index (but saving space is likely to waste time, ** time and space are irreconcilable contradictions **),As follows.

````SQL
create index idx_student_name_1 on tb_student(stuname(1));
````

The above index is equivalent to an index created based on the first word of the student's name. Let's take a look at the SQL execution plan.

````SQL
explain select * from tb_student where stuname='Lin Zhennan'\G
````

````
**************************** 1. row ******************** ******
id: 1
  select_type: SIMPLE
        table: tb_student
   partitions: NULL
         type: ref
possible_keys: idx_student_name
          key: idx_student_name
      key_len: 5
          ref: const
         rows: 2
     filtered: 100.00
        Extra: Using where
1 row in set, 1 warning (0.00 sec)
````

I don’t know if you have noticed that the rows scanned this time have become 2 rows, because there are two students with the surname “Lin” in the student table. If we only use the first word of the name as an index, we can pass the index when querying. will find these two lines.

If you want to drop the index, you can use the following SQL.

````SQL
alter table tb_student drop index idx_student_name;
````

or

````SQL
drop index idx_student_name on tb_student;
````

When creating an index, we can also use compound indexes and functional indexes (supported since MySQL 5.7). Using compound indexes to achieve **index coverage** can reduce unnecessary sorting and table return operations, which will improve the performance of the query. It has been doubled, and interested readers can study it by themselves.

We briefly summarize the design principles of the index for you:

1. **The most suitable columns for indexing are the columns that appear in the WHERE clause and join clause.
2. The larger the cardinality of the index column (more values ​​and fewer duplicate values), the better the indexing effect.
3. Using **prefix index** can reduce the space occupied by the index, and more indexes can be cached in memory.
4. **The more indexes the better**, although the index speeds up the read operation (query), the write operation (add, delete, modify) will become slower, because the change of the data will lead to the update of the index, just Just like the addition or deletion of chapters in a book, the table of contents needs to be updated.
5. When using the InnoDB storage engine, the ordinary index of the table will save the value of the primary key, so the primary key should be as short as possible. This can effectively reduce the space occupied by the index and improve the caching effect of the index.

Finally, there is one more point that needs to be explained. In the B-tree index used by InnoDB, the index of the numeric type column will take effect in addition to the equal value judgment. Use `>`, `<`, `>=`, `<=`, `BETWEEN...AND...`, `<>`, the index still works; for string type columns, if you use a fuzzy query that does not start with a wildcard, the index also works, but other situations will cause The index is invalid, which means that a full table query is likely to be done.

### view

A view is an object in a relational database that combines a result set composed of a set of query instructions into a queryable data table. Simply put, a view is a virtual table, but unlike a data table, a data table is an entity structure, and a view is a virtual structure. You can also understand a view as an SQL that is stored in the database and given a name statement.

Use views to get the following benefits:

1. The entity data table can be hidden, so that external programs cannot know the actual data structure, allowing visitors to use the components of the table instead of the entire table, reducing the risk of database attacks.
2. In most cases, the view is read-only (the operation of updating the view usually has many restrictions), and external programs cannot directly modify the data through the view.
3. Reuse SQL statements, wrap highly complex queries in view tables, and directly access the view to retrieve the required data; views can also be viewed as data tables for connection queries.
4. The view can return data in a different format from the entity data table, and the data can be formatted when the view is created.

Create a view.

````SQL
-- create a view
create view `vw_avg_score`
as
    select `stu_id`, round(avg(`score`), 1) as `avg_score`
    from `tb_record` group by `stu_id`;

-- create a view based on an existing view
create view `vw_student_score`
as
    select `stu_name`, `avg_score`
    from `tb_student` natural join `vw_avg_score`;
````

> **Tip**: Because views do not contain data, every time you use a view, you must execute a query to get the data. If you use join queries, nested queries to create more complex views, you may find that the query The performance drops drastically. Therefore, before using complex views, you should test to ensure that their performance meets the needs of your application.

Use views.

````SQL
select * from `vw_student_score` order by `avg_score` desc;
````

````
+-------------+------------+
| stuname | avgscore |
+-------------+------------+
| Yang Guo | 95.6 |
| Let me go | 53.5 |
| Wang Yuyan | 84.3 |
| Ji Yanran | 73.8 |
| Yue Buqun | 78.0 |
| Eastern Unbeaten | 88.0 |
| Xiang Shaolong | 92.0 |
+-------------+------------+
````

Since the view is a virtual table, can the data in the view be updated? Updability of views is case-by-case, and the following types of views cannot be updated:

1. Aggregate functions (`SUM`, `MIN`, `MAX`, `AVG`, `COUNT`, etc.), `DISTINCT`, `GROUP BY`, `HAVING`, `UNION`, or `UNION ALL` are used view.
2. `SELECT` contains views of subqueries.
3. The `FROM` clause contains a view that cannot be updated.
4. The subquery of the `WHERE` clause references a view of the table in the `FROM` clause.

Delete the view.

```SQL
drop view vw_student_score;
```

> **Note**: If you want to update the view, you can delete the view first with the above command, or you can update the view through `create or replace view`.

View rules and restrictions.

1. Views can be nested, and a new view can be constructed using data retrieved from other views. Views can also be used with tables.
2. The `order by` clause can be used when creating a view, but if `order by` is also used when retrieving data from a view, the original `order by` in the view will be overwritten.
3. Views cannot use indexes, and they will not trigger the execution of triggers (in actual development, due to performance and other considerations, triggers are generally not recommended, so we will not introduce this concept).

### functions

There are too many differences between functions in MySQL and functions in Python, because functions are used to encapsulate code that is relatively independent in function and will be reused. If you have to find some differences, then functions in MySQL can execute SQL statements. In the following example, we implement the function of truncating super-long strings through a custom function.

````SQL
delimiter $$

create function truncate_string(
    content varchar(10000),
    max_length int unsigned
) returns varchar(10000) no sql
begin
    declare result varchar(10000) default content;
    if char_length(content) > max_length then
        set result = left(content, max_length);
        set result = concat(result, '...');
    end if;
    return result;
end $$

delimiter;
````

> **Note 1**: The `no sql` after the function declaration is to declare that the function body does not use SQL statements; if the function body needs to read data through SQL, it needs to be declared as `reads sql data`.
>
> **Note 2**: The `delimiter` command before and after the function is defined to modify the delimiter, because the statements in the function body are all terminated with `;`. If the delimiter is not redefined, then the `;`, the code will be truncated and executed, obviously this is not the effect we want.

Call the custom function in the query.

````SQL
select truncate_string('Walk around the streets of Chengdu with me until all the lights go out', 10) as short_string;
````

````
+--------------------------------------+
| short_string |
+--------------------------------------+
| Walk with me on the streets of Chengdu... |
+--------------------------------------+
````

### process

A procedure (also known as a stored procedure) is a collection of SQL compiled and stored in the database in advance. The calling procedure can simplify the work of application developers, reduce communication with the database server, and improve the performance of data operations. helpful. In fact, the SQL statements we have used so far are single statements for one or more tables, but in actual development, we often encounter situations where an operation requires multiple SQL statements to complete. For example, when an e-commerce website accepts user orders, it needs to do the following series of processing.

1. Check whether there are corresponding items in the inventory and whether the inventory is sufficient by querying.
2. If there are items in stock, lock the stock to ensure those items are no longer sold to others, and reduce the number of items available to reflect the correct stock level.
3. If inventory is insufficient, further interaction with the supplier may be required or at least a system prompt message may be generated.
4. Regardless of whether the order is successfully accepted or not, a flow record needs to be generated, and a notification message needs to be generated for the corresponding user.

We can encapsulate complex operations through processes, which not only helps to ensure data consistency, but also if the business changes in the future, we only need to adjust and modify the process. To the user calling the procedure, the procedure does not expose the details of the data table, and the execution of the procedure is much faster than executing a set of SQL one by one.

The following procedure implements a query for the highest, lowest, and average scores for a course.

````SQL
drop procedure if exists sp_score_stat;

delimiter $$

create procedure sp_score_stat(
courseId int,
out maxScore decimal(4,1),
out minScore decimal(4,1),
out avgScore decimal(4,1)
)
begin
select max(score) into maxScore from tb_record where cou_id=courseId;
select min(score) into minScore from tb_record where cou_id=courseId;
select avg(score) into avgScore from tb_record where cou_id=courseId;
end $$

delimiter;
````

> **Note**: When defining a procedure, since it may be necessary to write multiple SQLs, a semicolon needs to be used as a separator to separate these SQLs. If at this time, a semicolon is still used to indicate the end of the entire code, then the definition of the procedure SQL errors will occur, so above we use `delimiter $$` to define the end of the entire code as `$$`, then the semicolon in the code will no longer indicate the end of the entire code, the entire code will only Executed when `end $$` is encountered. After defining the procedure, change the terminator back to a semicolon via `delimiter ;` (restore the scene).

The process defined above has four parameters. The first parameter is the input parameter, which represents the number of the course, and the following parameters are output parameters, because the process cannot define the return value, and the execution result can only be brought out through the output parameter. The keyword for output parameters is `out`, and the parameters are input parameters by default.

call procedure.

````SQL
call sp_score_stat(1111, @a, @b, @c);
````

Get the value of the output parameter.

````SQL
select @a as highest score, @b as lowest score, @c as average score;
````

delete process.

````SQL
drop procedure sp_score_stat;
````

In the process, we can define variables and conditions, use branch and loop statements, query results through cursor operations, and use event schedulers, which we will not introduce here for the time being. Although we have talked about the benefits of many processes, in actual development, if the process is frequently used and a large number of complex operations are put into the process, it will cause huge pressure on the database server, and the database is often the performance bottleneck. The use process is undoubtedly a worse operation. Therefore, for Internet product development, we generally recommend that the database is only stored, and the complex calculation and processing are left to the program on the application server to complete. If the application server becomes overwhelmed, we can easily deploy multiple applications. Servers to share these pressures.

If you are interested in the views, functions, and procedures mentioned above, including triggers that we have not mentioned, I suggest you read the MySQL introductory book ["MySQL must know and know"](https://item.jd. com/12818982.html) for general understanding, because these knowledge points may not be used in your future work, and you may learn them just to cope with the interview.

### MySQL New Features

#### JSON type

When many developers use relational databases for data persistence, they often feel that structured storage lacks flexibility, because all columns and corresponding data types must be designed in advance. In the process of business development and changes, if you need to modify the table structure, it is definitely more troublesome and uncomfortable. Since MySQL version 5.7, MySQL has introduced support for JSON data type (MySQL 8.0 solved the JSON log performance bottleneck). Using JSON type well is actually breaking the boundaries between relational databases and non-relational databases. It brings more convenience to data persistence operations.

JSON types are mainly divided into JSON objects and JSON arrays, as shown below.

1. JSON object

````JSON
{"name": "Luo Hao", "tel": "13122335566", "QQ": "957658"}
````

2. JSON array

````JSON
[1, 2, 3]
````

````JSON
[{"name": "Luo Hao", "tel": "13122335566"}, {"name": "Wang Dahui", "QQ": "123456"}]
````

Where do you need to use the JSON type? To give a simple example, users of many products now support multiple ways to log in, such as mobile phone numbers, WeChat, QQ, Sina Weibo, etc. However, under normal circumstances, we do not require users to provide all of this information, so use traditional , you need to design multiple columns to correspond to multiple login methods, and you may also need to allow null values ​​in these columns, which is obviously not a good choice; on the other hand, if the product adds another login method, then It is necessary to modify the previous table structure, which is even more painful. However, with the JSON type, the problem just now is solved, and we can make the design as shown below.

````SQL
create table `tb_test`
(
`user_id` bigint unsigned,
`login_info` json,
primary key (`user_id`)
) engine=innodb;

insert into `tb_test` values
    (1, '{"tel": "13122335566", "QQ": "654321", "wechat": "jackfrued"}'),
    (2, '{"tel": "13599876543", "weibo": "wangdachui123"}');
````

If you want to query the user's mobile phone and WeChat account, you can use the following SQL statement.

````SQL
select
    `user_id`,
    json_unquote(json_extract(`login_info`, '$.tel')) as phone number,
    json_unquote(json_extract(`login_info`, '$.wechat')) as WeChat
from `tb_test`;
````

````
+---------+-------------+------------+
| user_id | Mobile number | WeChat |
+---------+-------------+------------+
| 1 | 13122335566 | jackfrued |
|2|13599876543|NULL|
+---------+-------------+------------+
````

Because of its support for JSON types, MySQL also provides supporting functions for processing JSON data, such as `json_extract` and `json_unquote` used above. Of course, there is a more convenient way to write the above SQL, as shown below.

````SQL
select
`user_id`,
    `login_info` ->> '$.tel' as phone number,
    `login_info` ->> '$.wechat' as WeChat
from `tb_test`;
````

For another example, if our product wants to implement the user portrait function (labeling users), and then recommend platform services or consumer goods to users based on user portraits, we can also use JSON type to save user portrait data, The schematic code is shown below.

Create a portrait tag table.

````SQL
create table `tb_tags`
(
`tag_id` int unsigned not null comment 'tag_id',
`tag_name` varchar(20) not null comment 'tag name',
primary key (`tag_id`)
) engine=innodb;

insert into `tb_tags` (`tag_id`, `tag_name`)
values
    (1, 'after 70'),
    (2, 'After 80'),
    (3, 'Post-90'),
    (4, 'after 00'),
    (5, 'Love sports'),
    (6, 'Highly educated'),
    (7, 'petty bourgeoisie'),
    (8, 'Have a room'),
    (9, 'has a car'),
    (10, 'I love watching movies'),
    (11, 'Love online shopping'),
    (12, 'Frequently order takeaway');
````

Tag users.

````SQL
create table `tb_users_tags`
(
`user_id` bigint unsigned not null comment 'user_id',
`user_tags` json not null comment 'user tags'
) engine=innodb;

insert into `tb_users_tags` values
    (1, '[2, 6, 8, 10]'),
    (2, '[3, 10, 12]'),
    (3, '[3, 8, 9, 11]');
````

Next, let's take a look at the ingenuity of the JSON type through a set of queries.

1. Find the user ID of the movie lover (with the tag `10`).

    ````SQL
    select * from `tb_users` where 10 member of (user_tags->'$');
    ````

2. Query the user IDs of the post-80s generation (with the tag `2`) who like to watch movies (with the tag `10`).

    ````
    select * from `tb_users` where json_contains(user_tags->'$', '[2, 10]');

3. Inquire about the user IDs who like to watch movies or those born in the 1980s or 1990s.

    ````SQL
    select `user_id` from `tb_users_tags` where json_overlaps(user_tags->'$', '[2, 3, 10]');
    ````

> **Note**: The above query uses the `member of` predicate and two JSON functions, `json_contains` can check whether the JSON array contains the specified element, and `json_overlaps` can check whether the JSON array is the same as the specified array There are overlapping parts.

#### window functions

MySQL has supported window functions since 8.0. Most commercial databases and some open source databases have already provided support for window functions, and some also call them OLAP (Online Analysis and Processing) functions. related. In order to help you understand window functions, let's talk about the concept of windows first.

A window can be understood as a collection of records, and a window function is a special function that is executed on a collection of records that meet certain conditions. For each record, the function must be executed in this window. The window function and the aggregation function we mentioned above are easy to confuse. The main difference between the two is that the aggregation function aggregates multiple records into one record, and the window function is executed for each record, and the number of records will not change after execution. The window function is not just a few functions, it is a complete set of syntax, the function is only a part of the syntax, the basic syntax is as follows:

````SQL
<window function> over (partition by <column name for grouping> order by <column name for user sorting>)
````

In the above syntax, the following two functions can be placed in the position of the window function:

1. Dedicated window functions, including: `lead`, `lag`, `first_value`, `last_value`, `rank`, `dense_rank` and `row_number`, etc.
2. Aggregate functions, including: `sum`, `avg`, `max`, `min` and `count`, etc.

Here are a few simple examples of using window functions. We first use the SQL as shown below to build a database and a table.

````SQL
-- Create a database named hrs and specify the default character set
create database `hrs` default charset utf8mb4;

-- switch to hrs database
use `hrs`;

-- create department table
create table `tb_dept`
(
`dno` int not null comment 'Number',
`dname` varchar(10) not null comment 'name',
`dloc` varchar(20) not null comment 'Location',
primary key (`dno`)
);

-- insert 4 departments
insert into `tb_dept` values
    (10, 'Accounting Department', 'Beijing'),
    (20, 'R&D Department', 'Chengdu'),
    (30, 'Sales Department', 'Chongqing'),
    (40, 'Operation and Maintenance Department', 'Shenzhen');

-- create employee table
create table `tb_emp`
(
`eno` int not null comment 'employee number',
`ename` varchar(20) not null comment 'employee name',
`job` varchar(20) not null comment 'employee position',
`mgr` int comment 'Supervisor number',
`sal` int not null comment 'Employee monthly salary',
`comm` int comment 'Monthly allowance',
`dno` int not null comment 'Department number',
primary key (`eno`),
constraint `fk_emp_mgr` foreign key (`mgr`) references tb_emp (`eno`),
constraint `fk_emp_dno` foreign key (`dno`) references tb_dept (`dno`)
);


-- Insert 14 employees
insert into `tb_emp` values
    (7800, 'Zhang Sanfeng', 'President', null, 9000, 1200, 20),
    (2056, 'Qiao Feng', 'Analyst', 7800, 5000, 1500, 20),
    (3088, 'Li Mochou', 'Designer', 2056, 3500, 800, 20),
    (3211, 'Zhang Wuji', 'Programmer', 2056, 3200, null, 20),
    (3233, 'Qiu Chuji', 'programmer', 2056, 3400, null, 20),
    (3251, 'Zhang Cuishan', 'programmer', 2056, 4000, null, 20),
    (5566, 'Song Yuanqiao', 'Accountant', 7800, 4000, 1000, 10),
    (5234, 'Guo Jing', 'Cashier', 5566, 2000, null, 10),
    (3344, 'Huang Rong', 'Sales Supervisor', 7800, 3000, 800, 30),
    (1359, 'Hu Yidao', 'Salesman', 3344, 1800, 200, 30),
    (4466, 'Miao Renfeng', 'Salesman', 3344, 2500, null, 30),
    (3244, 'Ouyang Feng', 'Programmer', 3088, 3200, null, 20),
    (3577, 'Yang Guo', 'Accounting', 5566, 2200, null, 10),
    (3588, 'Zhu Jiuzhen', 'Accounting', 5566, 2500, null, 10);
````

Example 1: Query the names and monthly salaries of employees ranked 4th to 6th in descending order of monthly salary.

````SQL
select * from (
select
`ename`, `sal`,
row_number() over (order by `sal` desc) as `rank`
from `tb_emp`
) `temp` where `rank` between 4 and 6;
````

> **Note**: The function `row_number()` used above can generate a row number for each record, in actual work, it can be replaced with the `rank()` or `dense_rank()` function as needed, The difference between the three can be understood by referring to the official documents or reading ["Easy to Understand: SQL Window Functions"](https://zhuanlan.zhihu.com/p/92654574). In versions prior to MySQL 8, we could do something similar in the following way.
>
> ````SQL
> select `rank`, `ename`, `sal` from (
> select @a:=@a+1 as `rank`, `ename`, `sal`
> from `tb_emp`, (select @a:=0) as t1 order by `sal` desc
> ) t2 where `rank` between 4 and 6;
> ````

Example 2: Query the names and department names of the two employees with the highest monthly salary in each department.

````SQL
select `ename`, `sal`, `dname`
from (
    select
        `ename`, `sal`, `dno`,
        rank() over (partition by `dno` order by `sal` desc) as `rank`
    from `tb_emp`
) as `temp` natural join `tb_dept` where `rank`<=2;
````

> Description: In versions prior to MySQL 8, we can accomplish similar operations in the following ways.
>
> ````SQL
> select `ename`, `sal`, `dname` from `tb_emp` as `t1`
natural join `tb_dept`
where (
    select count(*) from `tb_emp` as `t2`
    where `t1`.`dno`=`t2`.`dno` and `t2`.`sal`>`t1`.`sal`
)<2 order by `dno` asc, `sal` desc;
> ````

###  Other content

#### Paradigm Theory

Paradigm theory is the guiding ideology for designing two-dimensional tables in relational databases.

1. First Normal Form: The value range of each column of the data table is composed of atomic values, which cannot be further divided.
2. Second normal form: All data in the data table must be completely dependent on the keys (primary key and candidate key) of the data table.
3. Third Normal Form: All non-key attributes are only related to candidate keys, that is to say, non-key attributes should be independent and unrelated.

> **Note**: In actual work, for the sake of efficiency, we are likely to make anti-paradigm design when designing tables, that is, deliberately reduce the mode level and add redundant data to obtain better operation performance.

#### Data Integrity

1. Entity Integrity - each entity is unique

   - primary key (`primary key`) / unique constraint (`unique`)
2. Referential Integrity (Referential Integrity) - References to non-existent entities are not allowed in the relationship

   - foreign key (`foreign key`)
3. Domain integrity - data is valid
   - data type and length

   - Not null constraint (`not null`)

   - default value constraint (`default`)

   - check constraints (`check`)

     > **Note**: Before MySQL 8.x, check constraints did not work.

#### Data Consistency

1. Transaction: A series of read/write operations to the database that either all succeed or all fail.

2. ACID properties of transactions
   - Atomicity: The transaction is executed as a whole, and either all or none of the operations on the database involved in it are executed
   - Consistency: Transactions should ensure that the state of the database changes from one consistent state to another consistent state
   - Isolation: When multiple transactions are executed concurrently, the execution of one transaction should not affect the execution of other transactions
   - Persistence: Modifications to the database by committed transactions should be permanently stored in the database
   
3. Transaction Operations in MySQL

   - Open transaction environment

     ````SQL
     start transaction
     ````

   - Commit transaction

     ````SQL
     commit
     ````

   - rollback transaction

     ````SQL
     rollback
     ````

4. Check the transaction isolation level

    ````SQL
    show variables like 'transaction_isolation';
    ````

    ````
    +----------------------+-----------------+
    | Variable_name | Value |
    +----------------------+-----------------+
    | transaction_isolation | REPEATABLE-READ |
    +----------------------+-----------------+
    ````

    It can be seen that MySQL's default transaction isolation level is `REPEATABLE-READ`.

5. Modify the (current session) transaction isolation level

    ````SQL
    set session transaction isolation level read committed;
    ````

    Re-check the transaction isolation level and the result is as follows.

    ````
    +----------------------+----------------+
    | Variable_name | Value |
    +----------------------+----------------+
    | transaction_isolation | READ-COMMITTED |
    +----------------------+----------------+
    ````

Transactions in relational databases are a big topic, because when there are multiple concurrent transactions accessing data, there may be three types of data read problems (dirty read, non-repeatable read, phantom read) and two types of update data. Problems (type 1 missing updates, type 2 missing updates). If you want to understand these five types of questions, you can read the first part of the article ["Java Interview Questions (Part 1)"](https://blog.csdn.net/jackfrued/article/details/44921941) published on the CSDN website 80 questions. In order to avoid these problems, the bottom layer of relational databases has a corresponding locking mechanism, which can be divided into table-level locks and row-level locks according to different lock objects, and shared locks and exclusive locks according to concurrent transaction locking relationships. However, it is very troublesome to use locks directly. For this reason, the database provides an automatic locking mechanism for users. As long as the user specifies an appropriate transaction isolation level, the database will analyze the SQL statement and then add appropriate locks to the resources accessed by the transaction. In addition, the database will maintain these locks to improve the performance of the system through various means, which are transparent to the user. If you want to know the details of MySQL transactions and locks, I recommend everyone to read the advanced book ["High Performance MySQL"](https://item.jd.com/11220393.html), which is also a classic book on databases.

The ANSI/ISO SQL 92 standard defines four levels of transaction isolation levels, as shown in the following table. It should be noted that the transaction isolation level and the concurrency of data access are opposite, the higher the transaction isolation level, the worse the concurrency. Therefore, it is necessary to determine which transaction isolation level to use according to the specific application. There is no universal principle in this place.

<img src="https://gitee.com/jackfrued/mypic/raw/master/20211121225327.png" style="zoom:50%;">

### Summarize

The knowledge about SQL and MySQL is definitely far more than those listed above, such as the optimization of SQL itself, MySQL performance tuning, MySQL operation and maintenance related tools, MySQL data backup and recovery, monitoring MySQL services, deploying high-availability architectures, etc. There is no way to discuss this series of issues one by one here, so I will leave it to explain when necessary, and readers can also explore on their own.