## Processes and threads

The computers we use today have already entered the multi-CPU or multi-core era, and the operating systems we use are operating systems that support "multitasking", which allows us to run multiple programs at the same time, or decompose a program into several relative Independent subtasks allow multiple subtasks to be executed concurrently, thereby shortening the execution time of the program and allowing users to obtain a better experience. Therefore, no matter what programming language is used for development at present, it should be one of the necessary skills for programmers to realize that the program can perform multiple tasks at the same time, which is often referred to as "concurrent programming". To do this, we need to discuss two concepts first, one is called a process and the other is called a thread.

### concept

A process is a program executed in the operating system. The operating system allocates storage space in units of processes. Each process has its own address space, data stack, and other auxiliary data used to track the execution of the process. The operating system manages the execution of all processes. , allocate resources reasonably for them. A process can create a new process to perform other tasks by fork or spawn, but the new process also has its own independent memory space, so data sharing must be achieved through the inter-process communication mechanism (IPC, Inter-Process Communication). Specific methods include pipes, signals, sockets, shared memory areas, etc.

A process can also have multiple concurrent execution threads. Simply put, it has multiple execution units that can be scheduled by the CPU, which are called threads. Because threads are under the same process, they can share the same context, so it is easier to share and communicate information between threads than processes. Of course, in a single-core CPU system, true concurrency is impossible, because only one thread can get the CPU at a certain time, and multiple threads share the execution time of the CPU. The benefits of using multi-threading to implement concurrent programming for programs are self-evident. The most important thing is to improve program performance and user experience. Almost all the software we use today uses multi-threading technology, which can be exploited. The system's own process monitoring tools (such as "Activity Monitor" in macOS, "Task Manager" in Windows) to confirm, as shown below.

![](./res/macos-monitor.png)

Of course, multi-threading is not without its disadvantages. From the perspective of other processes, multi-threaded programs are not friendly to other programs, because it takes up more CPU execution time, so other programs cannot get enough CPU execution time; On the one hand, from the developer's point of view, writing and debugging multi-threaded programs has higher requirements for developers, which is more difficult for beginners.

Python supports both multi-process and multi-threading, so there are three main ways to use Python to implement concurrent programming: multi-process, multi-thread, multi-process + multi-thread.

### Multiprocessing in Python

Unix and Linux operating systems provide the `fork()` system call to create a process. The `fork()` function is called by the parent process, and the child process is created. The child process is a copy of the parent process, but the child process has its own PID. The `fork()` function is very special. It returns twice. In the parent process, the PID of the child process can be obtained through the return value of the `fork()` function, and the return value in the child process is always 0. Python's os module provides the `fork()` function. Since the Windows system does not have a `fork()` call, to achieve cross-platform multi-process programming, you can use the `Process` class of the multiprocessing module to create child processes, and this module also provides more advanced encapsulation, such as batch starting processes Process pools (`Pool`), queues (`Queue`) and pipes (`Pipe`) for inter-process communication, etc.

Let's use an example of downloading a file to illustrate the difference between using multiple processes and not using multiple processes. Let's take a look at the following code first.

````Python
from random import randint
from time import time, sleep


def download_task(filename):
    print('Start downloading %s...' % filename)
    time_to_download = randint(5, 10)
    sleep(time_to_download)
    print('%s download completed! It took %d seconds' % (filename, time_to_download))


def main():
    start = time()
    download_task('Python from entry to hospitalization.pdf')
    download_task('Peking Hot.avi')
    end = time()
    print('It took %.2f seconds in total.' % (end - start))


if __name__ == '__main__':
    main()
````

Below is the result of one run obtained by running the program.

```Shell
Get started downloading Python from entry to hospital.pdf...
Python from entry to hospital.pdf download complete! It took 6 seconds
Start downloading Peking Hot.avi...
Peking Hot.avi download complete! It took 7 seconds
It took 13.01 seconds in total.
````

As can be seen from the above example, if the code in the program can only be executed bit by bit in sequence, even if two unrelated download tasks are executed, it is necessary to wait for the download of one file to complete before starting the next download. task, which is obviously unreasonable and inefficient. Next, we use the multi-process method to put the two download tasks into different processes, the code is as follows.

````Python
from multiprocessing import Process
from os import getpid
from random import randint
from time import time, sleep


def download_task(filename):
    print('Start the download process, process number [%d].' % getpid())
    print('Start downloading %s...' % filename)
    time_to_download = randint(5, 10)
    sleep(time_to_download)
    print('%s download completed! It took %d seconds' % (filename, time_to_download))


def main():
    start = time()
    p1 = Process(target=download_task, args=('Python from entry to hospital.pdf', ))
    p1.start()
    p2 = Process(target=download_task, args=('Peking Hot.avi', ))
    p2.start()
    p1.join()
    p2.join()
    end = time()
    print('It took %.2f seconds in total.' % (end - start))


if __name__ == '__main__':
    main()
````

In the above code, we create a process object through the `Process` class. Through the `target` parameter, we pass in a function to represent the code to be executed after the process starts. The latter `args` is a tuple, which represents Arguments passed to the function. The `start` method of the `Process` object is used to start the process, while the `join` method means to wait for the completion of the process execution. Running the above code can obviously find that the two download tasks are started "at the same time", and the execution time of the program will be greatly shortened, no longer the sum of the time of the two tasks. Below is the result of one execution of the program.

```Shell
Start the download process, process ID [1530].
Get started downloading Python from entry to hospital.pdf...
Start the download process, process ID [1531].
Start downloading Peking Hot.avi...
Peking Hot.avi download complete! It took 7 seconds
Python from entry to hospital.pdf download complete! It took 10 seconds
It took 10.01 seconds in total.
````

We can also use the classes and functions in the subprocess module to create and start subprocesses, and then communicate with the subprocesses through pipes. We will not explain these contents here, and interested readers can understand these knowledge by themselves. Next we will focus on how to implement the communication between the two processes. We start two processes, one outputs Ping, one outputs Pong, and the total of Ping and Pong output by the two processes adds up to 10. It sounds simple, but it would be wrong to write it this way.

````Python
from multiprocessing import Process
from time import sleep

counter = 0


def sub_task(string):
    global counter
    while counter < 10:
        print(string, end='', flush=True)
        counter += 1
        sleep(0.01)

        
def main():
    Process(target=sub_task, args=('Ping', )).start()
    Process(target=sub_task, args=('Pong', )).start()


if __name__ == '__main__':
    main()
````

It looks fine, but the final result is that Ping and Pong each output 10, why? When we create a process in the program, the child process copies the parent process and all its data structures. Each child process has its own independent memory space, which means that each of the two child processes has a `counter` variable. So the result is predictable. A simpler way to solve this problem is to use the `Queue` class in the multiprocessing module, which is a queue that can be shared by multiple processes. The bottom layer is implemented through pipes and the [semaphore]() mechanism. There are Interested readers can try it for themselves.


### Multithreading in Python

In the early version of Python, the thread module (now named _thread) was introduced to realize multi-threaded programming. However, this module is too low-level and many functions are not provided. Therefore, we recommend using the threading module for current multi-threaded development. Modules provide better object-oriented encapsulation for multithreaded programming. Let's implement the example of downloading a file just now in a multi-threaded manner.

````Python
from random import randint
from threading import Thread
from time import time, sleep


def download(filename):
    print('Start downloading %s...' % filename)
    time_to_download = randint(5, 10)
    sleep(time_to_download)
    print('%s download completed! It took %d seconds' % (filename, time_to_download))


def main():
    start = time()
    t1 = Thread(target=download, args=('Python from entry to hospital.pdf',))
    t1.start()
    t2 = Thread(target=download, args=('Peking Hot.avi',))
    t2.start()
    t1.join()
    t2.join()
    end = time()
    print('It took %.3f seconds in total' % (end - start))


if __name__ == '__main__':
    main()
````

We can directly use the `Thread` class of the threading module to create threads, but we talked about a very important concept called "inheritance" before. We can create new classes from existing classes, so we can also inherit from the `Thread` class. way to create a custom thread class, then create a thread object and start the thread. The code is shown below.

````Python
from random import randint
from threading import Thread
from time import time, sleep


class DownloadTask(Thread):

    def __init__(self, filename):
        super().__init__()
        self._filename = filename

    def run(self):
        print('Start downloading %s...' % self._filename)
        time_to_download = randint(5, 10)
        sleep(time_to_download)
        print('%s download completed! It took %d seconds' % (self._filename, time_to_download))


def main():
    start = time()
    t1 = DownloadTask('Python from entry to hospital.pdf')
    t1.start()
    t2 = DownloadTask('Peking Hot.avi')
    t2.start()
    t1.join()
    t2.join()
    end = time()
    print('It took %.2f seconds in total.' % (end - start))


if __name__ == '__main__':
    main()
````

Because multiple threads can share the memory space of the process, it is relatively simple to implement communication between multiple threads. The most direct way you can think of is to set a global variable, and multiple threads can share this global variable. But when multiple threads share the same variable (which we usually call a "resource"), it is very likely that uncontrollable results will result in the program failing or even crashing. If a resource is competitively used by multiple threads, we usually call it a "critical resource", and access to the "critical resource" needs to be protected, otherwise the resource will be in a "chaotic" state. The following example demonstrates the scenario of 100 threads transferring money (transferring 1 yuan) to the same bank account. In this example, the bank account is a critical resource. Without protection, we are likely to get errors. result.

````Python
from time import sleep
from threading import Thread


class Account(object):

    def __init__(self):
        self._balance = 0

    def deposit(self, money):
        # Calculate the balance after deposit
        new_balance = self._balance + money
        # It takes 0.01 seconds to simulate deposit acceptance
        sleep(0.01)
        # Modify account balance
        self._balance = new_balance

    @property
    def balance(self):
        return self._balance


class AddMoneyThread(Thread):

    def __init__(self, account, money):
        super().__init__()
        self._account = account
        self._money = money

    def run(self):
        self._account.deposit(self._money)


def main():
    account = Account()
    threads = []
    # Create a thread for 100 deposits to deposit money into the same account
    for _ in range(100):
        t = AddMoneyThread(account, 1)
        threads.append(t)
        t.start()
    # Wait for all deposit threads to finish executing
    for t in threads:
        t.join()
    print('The account balance is: ￥%d yuan' % account.balance)


if __name__ == '__main__':
    main()
````

Running the above program, the result is surprising. 100 threads transfer 1 yuan to the account, and the result is far less than 100 yuan. The reason for this is that we have not protected the "critical resource" of the bank account. When multiple threads deposit money into the account at the same time, they will execute the line of code `new_balance = self._balance + money` together. The account balances obtained by each thread are all `0` in the initial state, so the +1 operation is done on `0`, so the wrong result is obtained. In this case, "lock" can come in handy. We can protect "critical resources" through "locks". Only threads that acquire "locks" can access "critical resources", while other threads that do not get "locks" can only be blocked until the threads that acquire "locks" are released. With the "lock", other threads have the opportunity to obtain the "lock" and then access the protected "critical resources". The code below demonstrates how to use a "lock" to secure operations on a bank account to get the correct result.

````Python
from time import sleep
from threading import Thread, Lock


class Account(object):

    def __init__(self):
        self._balance = 0
        self._lock = Lock()

    def deposit(self, money):
        # Obtain the lock before executing subsequent code
        self._lock.acquire()
        try:
            new_balance = self._balance + money
            sleep(0.01)
            self._balance = new_balance
        finally:
            # Perform the operation of releasing the lock in finally to ensure that the normal abnormal lock can be released
            self._lock.release()

    @property
    def balance(self):
        return self._balance


class AddMoneyThread(Thread):

    def __init__(self, account, money):
        super().__init__()
        self._account = account
        self._money = money

    def run(self):
        self._account.deposit(self._money)


def main():
    account = Account()
    threads = []
    for _ in range(100):
        t = AddMoneyThread(account, 1)
        threads.append(t)
        t.start()
    for t in threads:
        t.join()
    print('The account balance is: ￥%d yuan' % account.balance)


if __name__ == '__main__':
    main()
````

It is a pity that Python's multi-threading cannot take full advantage of the multi-core feature of the CPU, which can be confirmed as long as a few threads that execute an infinite loop are started. The reason for this is because the Python interpreter has something called a "global interpreter lock" (GIL). Any thread must obtain the GIL lock before executing it, and then the interpreter automatically releases the GIL lock every 100 bytes of code. , allowing other threads to have a chance to execute, this is a historical problem, but even so, as we gave the example before, using multithreading is still positive in terms of improving execution efficiency and user experience.

### Multi-process or multi-thread

Whether it is multi-process or multi-threaded, as long as the number is large, the efficiency will definitely not go up, why? Let's take an analogy. Suppose you are unfortunately preparing for the high school entrance examination. Every night, you need to do homework in 5 subjects of Chinese, mathematics, English, physics, and chemistry. Each homework takes 1 hour. If you spend 1 hour doing the language homework first, then spend 1 hour doing the math homework, and then do all the homework in turn, and it will take a total of 5 hours. This method is called the single-task model. If you plan to switch to a multitasking model, you can do Chinese for 1 minute, then switch to math homework, do 1 minute, then switch to English, and so on, as long as the switching speed is fast enough, this method will be executed with a single-core CPU Multitasking is the same, from a spectator's point of view you are doing 5 assignments at the same time.

However, switching homework comes at a cost. For example, when switching from Chinese to mathematics, you must first clean up the Chinese books and pens on the desk (this is called saving the scene), then, open the mathematics textbook and find a compass ruler (this is called preparing for a new environment) ) to start doing math homework. The same is true for the operating system when switching processes or threads. It needs to save the current execution environment (CPU register state, memory page, etc.), and then prepare the execution environment of the new task (restore the last register state, switch memory pages, etc.) to start execution. Although this switching process is fast, it also takes time. If there are thousands of tasks running at the same time, the operating system may be mainly busy switching tasks, and there is not much time to execute tasks. Therefore, once the multitasking reaches a limit, it will cause the system performance to drop sharply, and eventually lead to the failure of all tasks.

The second consideration of whether to use multitasking is the type of task, which can be divided into computationally intensive and I/O intensive. Computation-intensive tasks are characterized by a lot of calculations and CPU resources consumption, such as encoding and decoding video or format conversion, etc. This kind of task depends entirely on the computing power of the CPU. The more time it takes to switch tasks, the less efficient the CPU is to perform tasks. Computation-intensive tasks mainly consume CPU resources. Such tasks are usually inefficient to execute in a scripting language such as Python. The C language is the most competent for such tasks. We mentioned earlier that Python has embedded C/C++ code. Mechanisms.

In addition to computing-intensive tasks, other tasks involving network and storage medium I/O can be regarded as I/O-intensive tasks. Such tasks are characterized by low CPU consumption and most of the time of the task is waiting for I/O The /O operation completes (because the speed of I/O is much lower than the speed of CPU and memory). For I/O-intensive tasks, if you start multitasking, you can reduce the I/O wait time and allow the CPU to run efficiently. There is a large class of tasks that are I/O-intensive, including network applications and web applications that we'll cover shortly.

> **Note:** The above content and examples come from ["Python Tutorial" on Liao Xuefeng's official website](https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000), because I hold some opinions in the author's article Different views, appropriate adjustments have been made to the text description of the original text.

### Single thread + asynchronous I/O

One of the most important improvements in modern operating systems for I/O operations is support for asynchronous I/O. If you take full advantage of the asynchronous I/O support provided by the operating system, you can use a single-process single-thread model to perform multitasking. This new model is called an event-driven model. Nginx is a web server that supports asynchronous I/O. It can efficiently support multitasking on a single-core CPU using a single-process model. On a multi-core CPU, you can run multiple processes (the same number as the number of CPU cores), taking full advantage of the multi-core CPU. Server-side programs developed with Node.js also use this working mode, which is also a popular solution for concurrent programming today.

In the Python language, the programming model of single thread + asynchronous I/O is called coroutine. With the support of coroutine, efficient multitasking programs can be written based on event-driven. The biggest advantage of coroutines is extremely high execution efficiency, because subroutine switching is not thread switching, but is controlled by the program itself, so there is no thread switching overhead. The second advantage of coroutines is that they do not require a multi-threaded locking mechanism, because there is only one thread, and there is no conflict of writing variables at the same time. There is no need to lock the shared resources in the coroutines, only the status needs to be judged, so execute Much more efficient than multithreading. If you want to make full use of the multi-core feature of the CPU, the easiest way is multi-process + coroutine, which not only makes full use of multi-core, but also gives full play to the high efficiency of coroutine, and can obtain extremely high performance. This aspect will be explained in subsequent courses.

### Applications

#### Example 1: Put time-consuming tasks into threads for a better user experience.

In the interface shown below, there are two buttons, "Download" and "About". It takes 10 seconds to download the file from the Internet by simulating clicking the "Download" button in a sleep mode. If you don't use "multi-threading", we will It is found that when the "download" button is clicked, other parts of the entire program are blocked by this time-consuming task and cannot be executed, which is obviously a very bad user experience. The code is as follows.

````Python
import time
import tkinter
import tkinter.messagebox


def download():
    # The simulated download task takes 10 seconds
    time.sleep(10)
    tkinter.messagebox.showinfo('Prompt', 'Download complete!')


def show_about():
    tkinter.messagebox.showinfo('About', 'Author: Luo Hao(v1.0)')


def main():
    top = tkinter.Tk()
    top.title('Single thread')
    top.geometry('200x150')
    top.wm_attributes('-topmost', True)

    panel = tkinter.Frame(top)
    button1 = tkinter.Button(panel, text='download', command=download)
    button1.pack(side='left')
    button2 = tkinter.Button(panel, text='about', command=show_about)
    button2.pack(side='right')
    panel.pack(side='bottom')

    tkinter.mainloop()


if __name__ == '__main__':
    main()
````

If multiple threads are used to execute time-consuming tasks in a separate thread, the main thread will not be blocked due to the execution of time-consuming tasks. The modified code is shown below.

````Python
import time
import tkinter
import tkinter.messagebox
from threading import Thread


def main():

    class DownloadTaskHandler(Thread):

        def run(self):
            time.sleep(10)
            tkinter.messagebox.showinfo('Prompt', 'Download complete!')
            # enable download button
            button1.config(state=tkinter.NORMAL)

    def download():
        # disable download button
        button1.config(state=tkinter.DISABLED)
        # Set the thread as a daemon thread through the daemon parameter (the main program will no longer retain execution when it exits)
        # Handle time-consuming download tasks in threads
        DownloadTaskHandler(daemon=True).start()

    def show_about():
        tkinter.messagebox.showinfo('About', 'Author: Luo Hao(v1.0)')

    top = tkinter.Tk()
    top.title('Single thread')
    top.geometry('200x150')
    top.wm_attributes('-topmost', 1)

    panel = tkinter.Frame(top)
    button1 = tkinter.Button(panel, text='download', command=download)
    button1.pack(side='left')
    button2 = tkinter.Button(panel, text='about', command=show_about)
    button2.pack(side='right')
    panel.pack(side='bottom')

    tkinter.mainloop()


if __name__ == '__main__':
    main()
````

#### Example 2: "Divide and Conquer" a complex task using multiple processes.

Let's complete the computationally intensive task of summing 1~100000000. The problem itself is very simple and can be solved with a little knowledge of loops. The code is as follows.

````Python
from time import time


def main():
    total = 0
    number_list = [x for x in range(1, 100000001)]
    start = time()
    for number in number_list:
        total += number
    print(total)
    end = time()
    print('Execution time: %.3fs' % (end - start))


if __name__ == '__main__':
    main()
````

In the above code, I deliberately created a list container and then filled in 100,000,000 numbers. This step is actually time-consuming, so for the sake of fairness, when we divide this task into 8 processes to execute When , we don't consider the time spent in the list slice operation for the time being, but only count the time spent doing the operation and merging the results of the operation. The code is as follows.

````Python
from multiprocessing import Process, Queue
from random import randint
from time import time


def task_handler(curr_list, result_queue):
    total = 0
    for number in curr_list:
        total += number
    result_queue.put(total)


def main():
    processes = []
    number_list = [x for x in range(1, 100000001)]
    result_queue = Queue()
    index = 0
    # Start 8 processes to slice the data and perform operations
    for _ in range(8):
        p = Process(target=task_handler,
                    args=(number_list[index:index + 12500000], result_queue))
        index += 12500000
        processes.append(p)
        p.start()
    # Start recording the time it takes for all processes to complete execution
    start = time()
    for p in processes:
        p.join()
    # Merge execution results
    total = 0
    while not result_queue.empty():
        total += result_queue.get()
    print(total)
    end = time()
    print('Execution time: ', (end - start), 's', sep='')


if __name__ == '__main__':
    main()
````

Compare the execution results of the two pieces of code (on the MacBook I am currently using, the above code takes about 6 seconds, while the following code takes less than 1 second, again, we are only comparing the operation time , regardless of the time spent in list creation and slicing operations), after using multi-process, because more CPU execution time is obtained and the multi-core feature of CPU is better utilized, the execution time of the program is significantly reduced, and the more the amount of computation The bigger the effect is, the more obvious it is. Of course, if you want, you can also deploy multiple processes on different computers to form distributed processes. The specific method is to share the `Queue` object through the network through the manager provided in the `multiprocessing.managers` module (registered Go to the network so that other computers can access), this part of the content is also left to the topic of crawler to explain.