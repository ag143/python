## Python language advanced

### Important knowledge points

- Usage of generative (derivative) expressions

  ````Python
  prices = {
      'AAPL': 191.88,
      'GOOG': 1186.96,
      'IBM': 149.24,
      'ORCL': 48.44,
      'ACN': 166.89,
      'FB': 208.09,
      'SYMC': 21.29
  }
  # Construct a new dictionary with stocks with stock prices greater than 100 yuan
  prices2 = {key: value for key, value in prices.items() if value > 100}
  print(prices2)
  ````

  > Explanation: Production (comprehension) can be used to generate lists, sets and dictionaries.

- nested lists of pits

  ````Python
  names = ['Guan Yu', 'Zhang Fei', 'Zhao Yun', 'Ma Chao', 'Huang Zhong']
  courses = ['Chinese', 'Math', 'English']
  # Enter the grades of five students for three courses
  # Error - see http://pythontutor.com/visualize.html#mode=edit
  # scores = [[None] * len(courses)] * len(names)
  scores = [[None] * len(courses) for _ in range(len(names))]
  for row, name in enumerate(names):
      for col, course in enumerate(courses):
          scores[row][col] = float(input(f'Please enter {course} score of {name}: '))
          print(scores)
  ````

  [Python Tutor](http://pythontutor.com/) - VISUALIZE CODE AND GET LIVE HELP

- `heapq` module (heapsort)

  ````Python
  """
  Find the largest or smallest N elements from a list
  Heap structure (big root heap/small root heap)
  """
  import heapq
  
  list1 = [34, 25, 12, 99, 87, 63, 58, 78, 88, 92]
  list2 = [
      {'name': 'IBM', 'shares': 100, 'price': 91.1},
      {'name': 'AAPL', 'shares': 50, 'price': 543.22},
      {'name': 'FB', 'shares': 200, 'price': 21.09},
      {'name': 'HPQ', 'shares': 35, 'price': 31.75},
      {'name': 'YHOO', 'shares': 45, 'price': 16.35},
      {'name': 'ACME', 'shares': 75, 'price': 115.65}
  ]
  print(heapq.nlargest(3, list1))
  print(heapq.nsmallest(3, list1))
  print(heapq.nlargest(2, list2, key=lambda x: x['price']))
  print(heapq.nlargest(2, list2, key=lambda x: x['shares']))
  ````

- `itertools` module

  ````Python
  """
  Iteration tool module
  """
  import itertools
  
  # Generate full permutation of ABCD
  itertools.permutations('ABCD')
  # Generate a three-of-five combination of ABCDE
  itertools.combinations('ABCDE', 3)
  # Generate the Cartesian product of ABCD and 123
  itertools.product('ABCD', '123')
  # Generate infinite loop sequence of ABC
  itertools.cycle(('A', 'B', 'C'))
  ````

- `collections` module

  Commonly used tools:

  - `namedtuple`: A tuple of commands, which is a class factory that accepts a name of a type and a list of properties to create a class.
  - `deque`: A double-ended queue, which is an alternative implementation of a list. The bottom layer of list in Python is implemented based on arrays, while the bottom layer of deque is a doubly linked list, so when you need to add and delete elements at the head and tail, deque will show better performance, and the asymptotic time complexity is $O( 1) $.
  - `Counter`: a subclass of `dict`, the key is the element, the value is the count of the element, and its `most_common()` method can help us get the element with the highest frequency. I think the inheritance relationship between `Counter` and `dict` is debatable. According to the CARP principle, it is more reasonable to design the relationship between `Counter` and `dict` as an association relationship.
  - `OrderedDict`: a subclass of `dict`, which records the order in which key-value pairs are inserted, and appears to have both dictionary and linked list behavior.
  - `defaultdict`: Similar to the dictionary type, but the default value corresponding to the key can be obtained through the default factory function, which is more efficient than the `setdefault()` method in the dictionary.

  ````Python
  """
  Find the most frequent element in a sequence
  """
  from collections import Counter
  
  words = [
      'look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes',
      'the', 'eyes', 'the', 'eyes', 'the', 'eyes', 'not', 'around',
      'the', 'eyes', "don't", 'look', 'around', 'the', 'eyes',
      'look', 'into', 'my', 'eyes', "you're", 'under'
  ]
  counter = Counter(words)
  print(counter.most_common(3))
  ```

### Data Structures and Algorithms

- Algorithms: methods and steps to solve problems

- Evaluate the quality of the algorithm: asymptotic time complexity and asymptotic space complexity.

- Big O notation for asymptotic time complexity:
  - <img src="http://latex.codecogs.com/gif.latex?O(c)" /> - Constant time complexity - Bloom filter / Hash storage
  - <img src="http://latex.codecogs.com/gif.latex?O(log_2n)" /> - logarithmic time complexity - halved search (binary search)
  - <img src="http://latex.codecogs.com/gif.latex?O(n)" /> - Linear Time Complexity - Sequential Search / Count Sort
  - <img src="http://latex.codecogs.com/gif.latex?O(n*log_2n)" /> - Logarithmic Linear Time Complexity - Advanced Sorting Algorithms (Merge Sort, Quick Sort)
  - <img src="http://latex.codecogs.com/gif.latex?O(n^2)" /> - Squared time complexity - Simple sorting algorithm (selection sort, insertion sort, bubble sort)
  - <img src="http://latex.codecogs.com/gif.latex?O(n^3)" /> - Cubic Time Complexity - Floyd's Algorithm / Matrix Multiplication
  - <img src="http://latex.codecogs.com/gif.latex?O(2^n)" /> - Geometric series time complexity - Tower of Hanoi
  - <img src="http://latex.codecogs.com/gif.latex?O(n!)" /> - Factorial Time Complexity - Traveling Dealer Problem - NPC

  ![](./res/algorithm_complexity_1.png)

  ![](./res/algorithm_complexity_2.png)

- Sorting algorithms (selection, bubbling and merging) and search algorithms (ordering and halving)

  ````Python
  def select_sort(items, comp=lambda x, y: x < y):
      """Simple selection sort"""
      items = items[:]
      for i in range(len(items) - 1):
          min_index = i
          for j in range(i + 1, len(items)):
              if comp(items[j], items[min_index]):
                  min_index = j
          items[i], items[min_index] = items[min_index], items[i]
      return items
  ````

  ````Python
  def bubble_sort(items, comp=lambda x, y: x > y):
      """Bubble Sort"""
      items = items[:]
      for i in range(len(items) - 1):
          swapped = False
          for j in range(len(items) - 1 - i):
              if comp(items[j], items[j + 1]):
                  items[j], items[j + 1] = items[j + 1], items[j]
                  swapped = True
          if not swapped:
              break
      return items
  ````

  ````Python
  def bubble_sort(items, comp=lambda x, y: x > y):
      """Stir Sort (Bubble Sort Upgrade)"""
      items = items[:]
      for i in range(len(items) - 1):
          swapped = False
          for j in range(len(items) - 1 - i):
              if comp(items[j], items[j + 1]):
                  items[j], items[j + 1] = items[j + 1], items[j]
                  swapped = True
          if swapped:
              swapped = False
              for j in range(len(items) - 2 - i, i, -1):
                  if comp(items[j - 1], items[j]):
                      items[j], items[j - 1] = items[j - 1], items[j]
                      swapped = True
          if not swapped:
              break
      return items
  ````

  ````Python
  def merge(items1, items2, comp=lambda x, y: x < y):
      """Merge (merge two ordered lists into one ordered list)"""
      items = []
      index1, index2 = 0, 0
      while index1 < len(items1) and index2 < len(items2):
          if comp(items1[index1], items2[index2]):
              items.append(items1[index1])
              index1 += 1
          else:
              items.append(items2[index2])
              index2 += 1
      items += items1[index1:]
      items += items2[index2:]
      return items
  
  
  def merge_sort(items, comp=lambda x, y: x < y):
      return _merge_sort(list(items), comp)
  
  
  def _merge_sort(items, comp):
      """Merge Sort"""
      if len(items) < 2:
          return items
      mid = len(items) // 2
      left = _merge_sort(items[:mid], comp)
      right = _merge_sort(items[mid:], comp)
      return merge(left, right, comp)
  ````

  ````Python
  def seq_search(items, key):
      """Search order"""
      for index, item in enumerate(items):
          if item == key:
              return index
      return -1
  ````

  ````Python
  def bin_search(items, key):
      """Find in half"""
      start, end = 0, len(items) - 1
      while start <= end:
          mid = (start + end) // 2
          if key > items[mid]:
              start = mid + 1
          elif key < items[mid]:
              end = mid - 1
          else:
              return mid
      return -1
  ````

- Common Algorithms:

  - Exhaustive method - Also known as brute force method, all possibilities are tested until the correct answer is found.
  - Greedy method - when solving a problem, always do what is currently seen
  - The best choice, do not pursue the optimal solution, and quickly find a satisfactory solution.
  - Divide and conquer method - divide a complex problem into two or more identical or similar sub-problems, then divide the sub-problems into smaller sub-problems until they can be solved directly, and finally combine the solutions of the sub-problems get the solution to the original problem.
  - Backtracking method - Backtracking method, also known as heuristic method, searches forward according to the optimal conditions. When the search reaches a certain step and finds that the original choice is not optimal or fails to achieve the goal, it will go back a step and re-select.
  - Dynamic programming - The basic idea is to decompose the problem to be solved into several sub-problems, solve and save the solutions of these sub-problems first, to avoid a large number of repeated operations.

  Examples of exhaustive methods: one hundred money and one hundred chickens and five people sharing fish.

  ````Python
  # 5 yuan for a rooster, 3 yuan for a hen, 1 yuan for three chickens
  # Buy 100 chickens with 100 yuan and ask how many roosters/hens/chickens
  for x in range(20):
      for y in range(33):
          z = 100 - x - y
          if 5 * x + 3 * y + z // 3 == 100 and z % 3 == 0:
              print(x, y, z)
  
  # A, B, C, D, E five people fishing together one night and finally exhausted and sleep separately
  # The next day A wakes up first, he divides the fish into 5 pieces, throws away the extra piece, and takes his own piece
  # B wakes up the second time, also divides the fish into 5 portions, throws away the extra one, and takes his own portion
  # Then C, D, E wake up in turn and divide the fish in the same way and ask them how many fish they have caught at least
  fish = 6
  while True:
      total = fish
      enough = True
      for _ in range(5):
          if (total - 1) % 5 == 0:
              total = (total - 1) // 5 * 4
          else:
              enough = False
              break
      if enough:
          print(fish)
          break
      fish += 5
  ````

  Example of Greedy Law: Suppose a thief has a backpack that can hold up to 20 kilograms of stolen goods. He breaks into a house and finds the items shown in the table below. Obviously, he can't fit everything into the backpack, so he has to decide what to take and what to leave behind.

  | Name | Price (USD) | Weight (kg) |
  | :----: | :----------: | :------------: |
  | Computer | 200 | 20 |
  | Radio | 20 | 4 |
  | Clock | 175 | 10 |
  | Vase | 50 | 2 |
  | Books | 10 | 1 |
  | Oil Painting | 90 | 9 |

  ````Python
  """
  Greedy method: When solving a problem, always make the best choice in the current view, do not pursue the optimal solution, and quickly find a satisfactory solution.
  enter:
  20 6
  Computer 200 20
  Radio 20 4
  Bell 175 10
  Vase 50 2
  Book 10 1
  Oil Painting 90 9
  """
  class Thing(object):
      """thing"""
  
      def __init__(self, name, price, weight):
          self.name = name
          self.price = price
          self.weight = weight
  
      @property
      def value(self):
          """Price to weight ratio"""
          return self.price / self.weight
  
  
  def input_thing():
      """Enter item information"""
      name_str, price_str, weight_str = input().split()
      return name_str, int(price_str), int(weight_str)
  
  
  def main():
      """Main function"""
      max_weight, num_of_things = map(int, input().split())
      all_things = []
      for _ in range(num_of_things):
          all_things.append(Thing(*input_thing()))
      all_things.sort(key=lambda x: x.value, reverse=True)
      total_weight = 0
      total_price = 0
      for thing in all_things:
          if total_weight + thing.weight <= max_weight:
              print(f'The thief took {thing.name}')
              total_weight += thing.weight
              total_price += thing.price
      print(f'Total value: {total_price}$')
  
  
  if __name__ == '__main__':
      main()
  ````

Divide and conquer example: [Quick Sort](https://zh.wikipedia.org/zh/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F).

  ````Python
  """
  Quick Sort - Select the pivot to divide the elements, the left is smaller than the pivot and the right is larger than the pivot
  """
  def quick_sort(items, comp=lambda x, y: x <= y):
      items = list(items)[:]
      _quick_sort(items, 0, len(items) - 1, comp)
      return items
  
  
  def _quick_sort(items, start, end, comp):
      if start < end:
          pos = _partition(items, start, end, comp)
          _quick_sort(items, start, pos - 1, comp)
          _quick_sort(items, pos + 1, end, comp)
  
  
  def _partition(items, start, end, comp):
      pivot = items[end]
      i = start - 1
      for j in range(start, end):
          if comp(items[j], pivot):
              i += 1
              items[i], items[j] = items[j], items[i]
      items[i + 1], items[end] = items[end], items[i + 1]
      return i + 1
  ````

  Example of backtracking: [Knight Patrol](https://zh.wikipedia.org/zh/%E9%AA%91%E5%A3%AB%E5%B7%A1%E9%80%BB).

  ````Python
  """
  Recursive backtracking method: It is called heuristic method. It searches forward according to the optimal conditions. When a certain step is reached, when it is found that the original choice is not optimal or the goal is not achieved, it will go back a step and re-select. The more classic problems include knight patrol. , Eight Queens and Maze Pathfinding etc.
  """
  import sys
  import time
  
  SIZE = 5
  total = 0
  
  
  def print_board(board):
      for row in board:
          for col in row:
              print(str(col).center(4), end='')
          print()
  
  
  def patrol(board, row, col, step=1):
      if row >= 0 and row < SIZE and \
          col >= 0 and col < SIZE and \
          board[row][col] == 0:
          board[row][col] = step
          if step == SIZE * SIZE:
              global total
              total += 1
              print(f'{total}th move: ')
              print_board(board)
          patrol(board, row - 2, col - 1, step + 1)
          patrol(board, row - 1, col - 2, step + 1)
          patrol(board, row + 1, col - 2, step + 1)
          patrol(board, row + 2, col - 1, step + 1)
          patrol(board, row + 2, col + 1, step + 1)
          patrol(board, row + 1, col + 2, step + 1)
          patrol(board, row - 1, col + 2, step + 1)
          patrol(board, row - 2, col + 1, step + 1)
          board[row][col] = 0
  
  
  def main():
      board = [[0] * SIZE for _ in range(SIZE)]
      patrol(board, SIZE - 1, SIZE - 1)
  
  
  if __name__ == '__main__':
      main()
  ````
  
Dynamic programming example: the maximum value of the sum of the elements of a sublist.

  > Description: A sublist refers to a list composed of elements with consecutive indices (subscripts) in the list; the elements in the list are of type int, which may contain positive integers, 0, and negative integers; the program inputs the elements in the list and outputs the sublist The maximum value of element-wise summation, for example:
  >
  > Input: 1 -2 3 5 -3 2
  >
  > output: 8
  >
  > Input: 0 -2 3 5 -1 2
  >
  > output: 9
  >
  > Enter: -9 -2 -3 -5 -3
  >
  > output: -2

  ````Python
  def main():
      items = list(map(int, input().split()))
      overall = partial = items[0]
      for i in range(1, len(items)):
          partial = max(items[i], partial + items[i])
          overall = max(partial, overall)
      print(overall)
  
  
  if __name__ == '__main__':
      main()
  ````

  > **Note**: The easiest solution to this problem is to use a double loop, but the time performance of the code will become very bad. Using the idea of ​​dynamic programming, just using two more variables turns the original $O(N^2)$ complexity problem into $O(N)$.

### How to use the function

- Treat functions as "first-class citizens"

  - Functions can be assigned to variables
  - Functions can be used as arguments to functions
  - Functions can be used as return values ​​of functions

- usage of higher-order functions (`filter`, `map` and their replacements)

  ````Python
  items1 = list(map(lambda x: x ** 2, filter(lambda x: x % 2, range(1, 10))))
  items2 = [x ** 2 for x in range(1, 10) if x % 2]
  ````

- Positional parameters, variadic parameters, keyword parameters, named keyword parameters

- Meta information for parameters (code readability issues)

- Usage of anonymous functions and inline functions (`lambda` functions)

- Closures and scope issues

  - LEGB order of Python search variables (Local >>> Embedded >>> Global >>> Built-in)

  - The role of the `global` and `nonlocal` keywords

    `global`: declare or define a global variable (either directly use an existing global scope variable, or define a variable and place it in the global scope).

    `nonlocal`: declare a variable that uses a nested scope (the variable must exist in the nested scope, otherwise an error will be reported).

- Decorator functions (using decorators and undecorators)

  Example: a decorator that outputs the execution time of a function.

  ````Python
  def record_time(func):
      """Decorator for custom decorated function"""
      
      @wraps(func)
      def wrapper(*args, **kwargs):
          start = time()
          result = func(*args, **kwargs)
          print(f'{func.__name__}: {time() - start}seconds')
          return result
          
      return wrapper
  ````

  If the decorator does not wish to be coupled to the `print` function, you can write a parameterizable decorator.

````Python
  from functools import wraps
  from time import time
  
  
  def record(output):
      """Parameterizable decorator"""
  
  def decorate(func):
  
  @wraps(func)
  def wrapper(*args, **kwargs):
  start = time()
  result = func(*args, **kwargs)
  output(func.__name__, time() - start)
  return result
              
  return wrapper
  
  return decorate
  ````

  ````Python
  from functools import wraps
  from time import time
  
  
  class Record():
      """Define a decorator by defining a class"""
  
      def __init__(self, output):
          self.output = output
  
      def __call__(self, func):
  
          @wraps(func)
          def wrapper(*args, **kwargs):
              start = time()
              result = func(*args, **kwargs)
              self.output(func.__name__, time() - start)
              return result
  
          return wrapper
  ````

  > **Note**: Since the @wraps decorator is added to the decorated function, the function or class before being decorated can be obtained through `func.__wrapped__` to cancel the effect of the decorator.

  Example: Implementing the singleton pattern with decorators.

  ````Python
  from functools import wraps
  
  
  def singleton(cls):
      """Decorator class decorator"""
      instances = {}
  
      @wraps(cls)
      def wrapper(*args, **kwargs):
          if cls not in instances:
              instances[cls] = cls(*args, **kwargs)
          return instances[cls]
  
      return wrapper
  
  
  @singleton
  class President:
      """President (singleton class)"""
      pass
  ````

  > **Hint**: Closures are used in the above code, I don't know if you are aware of it. There is no small problem that the above code does not implement a thread-safe singleton. What should I do if I want to implement a thread-safe singleton?

  Thread-safe singleton decorator.

  ````Python
  from functools import wraps
  from threading import RLock
  
  
  def singleton(cls):
      """Thread-safe singleton decorator"""
      instances = {}
      locker = RLock()
  
      @wraps(cls)
      def wrapper(*args, **kwargs):
          if cls not in instances:
              with locker:
                  if cls not in instances:
                      instances[cls] = cls(*args, **kwargs)
          return instances[cls]
  
      return wrapper
  ````

  > **Hint**: The above code uses the `with` context syntax for lock operations, because the lock object itself is a context manager object (supports `__enter__` and `__exit__` magic methods). In the `wrapper` function, we first do a check without a lock, and then do a check with a lock. This is better than a direct lock check. If the object has already been created, there is no need to lock it again. Just return the object directly.


### Object-oriented knowledge

- Three pillars: encapsulation, inheritance, polymorphism

  Example: Payroll settlement system.

  ````Python
  """
  Monthly salary settlement system - department manager 15000 per month, programmer 200 per hour, salesperson 1800 basic salary plus 5% commission on sales
  """
  from abc import ABCMeta, abstractmethod
  
  
  class Employee(metaclass=ABCMeta):
      """Employee (abstract class)"""
  
      def __init__(self, name):
          self.name = name
  
      @abstractmethod
      def get_salary(self):
          """Pay monthly salary (abstract method)"""
          pass
  
  
  class Manager(Employee):
      """Department manager"""
  
      def get_salary(self):
          return 15000.0
  
  
  class Programmer(Employee):
      """programmer"""
  
      def __init__(self, name, working_hour=0):
          self.working_hour = working_hour
          super().__init__(name)
  
      def get_salary(self):
          return 200.0 * self.working_hour
  
  
  class Salesman(Employee):
      """Seller"""
  
      def __init__(self, name, sales=0.0):
          self.sales = sales
          super().__init__(name)
  
      def get_salary(self):
          return 1800.0 + self.sales * 0.05
  
  
  class EmployeeFactory:
      """Create a factory for employees (factory pattern - decoupling between object consumers and objects through factories)"""
  
      @staticmethod
      def create(emp_type, *args, **kwargs):
          """Create employee"""
          all_emp_types = {'M': Manager, 'P': Programmer, 'S': Salesman}
          cls = all_emp_types[emp_type.upper()]
          return cls(*args, **kwargs) if cls else None
  
  
  def main():
      """Main function"""
      emps = [
          EmployeeFactory.create('M', 'Cao Cao'),
          EmployeeFactory.create('P', 'Xun Yu', 120),
          EmployeeFactory.create('P', 'Guo Jia', 85),
          EmployeeFactory.create('S', 'Dianwei', 123000),
      ]
      for emp in emps:
          print(f'{emp.name}: {emp.get_salary():.2f} yuan')
  
  
  if __name__ == '__main__':
      main()
  ````

- Relationships between classes

  - is-a relationship: inheritance
  - has-a relationship: association/aggregation/composition
  - use-a relationship: dependency

  Example: Poker game.

````Python
  """
  Experience: symbolic constants are always better than literal constants, enum types are the best choice for defining symbolic constants
  """
  from enum import Enum, unique
  
  import random
  
  
  @unique
  class Suite(Enum):
      """Colors"""
  
      SPADE, HEART, CLUB, DIAMOND = range(4)
  
      def __lt__(self, other):
          return self.value < other.value
  
  
  class Card():
      """Card"""
  
      def __init__(self, suite, face):
          """Initialization method"""
          self.suite = suite
          self.face = face
  
      def show(self):
          """Display card face"""
          suites = ['♠︎', '♥︎', '♣︎', '♦︎']
          faces = ['', 'A', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K']
          return f'{suites[self.suite.value]}{faces[self.face]}'
  
      def __repr__(self):
          return self.show()
  
  
  class Poker():
      """poker"""
  
      def __init__(self):
          self.index = 0
          self.cards = [Card(suite, face)
                        for suite in Suite
                        for face in range(1, 14)]
  
      def shuffle(self):
          """Shuffle (random order)"""
          random.shuffle(self.cards)
          self.index = 0
  
      def deal(self):
          """Licensing"""
          card = self.cards[self.index]
          self.index += 1
          return card
  
      @property
      def has_more(self):
          return self.index < len(self.cards)
  
  
  class Player():
      """Player"""
  
      def __init__(self, name):
          self.name = name
          self.cards = []
  
      def get_one(self, card):
          """Draw a card"""
          self.cards.append(card)
  
      def sort(self, comp=lambda card: (card.suite, card.face)):
          """Organize the cards in hand"""
          self.cards.sort(key=comp)
  
  
  def main():
      """Main function"""
      poker = Poker()
      poker.shuffle()
      players = [Player('East evil'), Player('West poison'), Player('South Emperor'), Player('North beggar')]
      while poker.has_more:
          for player in players:
                  player.get_one(poker.deal())
      for player in players:
          player.sort()
          print(player.name, end=': ')
          print(player.cards)
  
  
  if __name__ == '__main__':
      main()
  ````

  > **Notes**: Emoji characters are used in the above code to represent the four suits of playing cards, which may not be displayed on some systems that do not support Emoji characters.

- Copy of objects (deep copy/deep copy/deep clone and shallow copy/shallow copy/shadow clone)

- Garbage collection, circular and weak references

Python uses automatic memory management, which is based on **reference counting**, and also introduces **mark-sweep** and **generational collection** strategies supplemented by two mechanisms.

  ````C
  typedef struct _object {
      /* reference count */
      int ob_refcnt;
      /* object pointer */
      struct _typeobject *ob_type;
  } PyObject;
  ````

  ````C
  /* macro definition that increments the reference count */
  #define Py_INCREF(op) ((op)->ob_refcnt++)
  /* Decrease reference count macro definition */
  #define Py_DECREF(op) \ //decrement count
      if (--(op)->ob_refcnt != 0) \
          ; \
      else \
          __Py_Dealloc((PyObject *)(op))
  ````

  Situations that result in reference count +1:

  - the object is created, e.g. `a = 23`
  - the object is referenced, e.g. `b = a`
  - Objects are passed as arguments to a function, e.g. `f(a)`
  - The object is stored as an element in a container, e.g. `list1 = [a, a]`

  Situations that result in a reference count of -1:

  - the alias of the object is explicitly destroyed, e.g. `del a`
  - the alias of the object is given to the new object, e.g. `a=24`
  - An object leaves its scope, such as when the f function finishes executing, the local variables in the f function (the global variables do not)
  - the container the object is in is destroyed, or the object is removed from the container

  Reference counting can cause problems with circular references, which can lead to memory leaks, as shown in the code below. To solve this problem, "mark-sweep" and "generational collection" were introduced in Python. When an object is created, the object is placed in the first generation. If the object survives the garbage check of the first generation, the object will be placed in the second generation. Similarly, the garbage in the second generation If the object survives the check, the object will be placed in the third generation.

  ````Python
  # Circular references can lead to memory leaks - Python also introduces mark cleanup and generational recycling in addition to reference technology
  # Before Python 3.6, if overriding the __del__ magic method will cause circular reference handling to fail
  # If you don't want to cause circular references, you can use weak references
  list1 = []
  list2 = []
  list1.append(list2)
  list2.append(list1)
  ````

  Garbage collection occurs when:

  - call `gc.collect()`
  - The counter of the `gc` module reaches the threshold
  - program exit

  If both objects in a circular reference define the `__del__` method, the `gc` module will not destroy these unreachable objects, because the gc module does not know which object's `__del__` method should be called first, this problem gets in Python 3.6 solved.

  The problem of circular references can also be solved by constructing weak references through the `weakref` module.

- Magic properties and methods (please refer to "Python Magic Methods Guide")

  There are a few small questions for you to think about:

  - Can custom objects use operators to perform operations?
  - Can custom objects be placed in `set`? Can you go heavy?
  - Can custom objects be used as keys in `dict`?
  - Can custom objects use contextual syntax?

- Mixin

  Example: A custom dictionary restricts key-value pairs to be set in the dictionary only if the specified key does not exist.

  ````Python
  class SetOnceMappingMixin:
      """Custom mixin class"""
      __slots__ = ()
  
      def __setitem__(self, key, value):
          if key in self:
              raise KeyError(str(key) + 'already set')
          return super().__setitem__(key, value)
  
  
  class SetOnceDict(SetOnceMappingMixin, dict):
      """Custom Dictionary"""
      pass
  
  
  my_dict= SetOnceDict()
  try:
      my_dict['username'] = 'jackfrued'
      my_dict['username'] = 'hellokitty'
  except KeyError:
      pass
  print(my_dict)
  ````

- Metaprogramming and metaclasses

  Objects are created through classes, and classes are created through metaclasses, which provide meta information for creating classes. All classes inherit directly or indirectly from `object`, and all metaclasses inherit directly or indirectly from `type`.

  Example: Implementing the Singleton pattern with a metaclass.

````Python
  import threading
  
  
  class SingletonMeta(type):
      """Custom metaclass"""
  
      def __init__(cls, *args, **kwargs):
          cls.__instance = None
          cls.__lock = threading.RLock()
          super().__init__(*args, **kwargs)
  
      def __call__(cls, *args, **kwargs):
          if cls.__instance is None:
              with cls.__lock:
                  if cls.__instance is None:
                      cls.__instance = super().__call__(*args, **kwargs)
          return cls.__instance
  
  
  class President(metaclass=SingletonMeta):
      """President (singleton class)"""
      
      pass
  ````

- Object Oriented Design Principles

  - Single Responsibility Principle (**S**RP) - A class only does what it is supposed to do (classes should be designed with high cohesion)
  - Open-Closed Principle (**O**CP) - Software entities should be closed to extension development and modification
  - Dependency Inversion Principle (DIP) - Abstraction-oriented programming (has been weakened in weakly typed languages)
  - Liskov Substitution Principle (**L**SP) - Subclass objects can be substituted for superclass objects at any time
  - Interface Segregation Principle (**I**SP) - The interface should be small but not large and complete (there is no concept of interface in Python)
  - Synthetic Aggregate Reuse Principle (CARP) - Prioritize the use of strong associations over inheritance to reuse code
  - Principle of Least Knowledge (Law of Demeter, Lo**D**) - Don't message people who are not necessarily connected

  > **Description**: The bolded letters above are called object-oriented **SOLID** principles.

- GoF design pattern

  - Creational patterns: singleton, factory, builder, prototype
  - Structural patterns: adapters, facades (facades), proxies
  - Behavioral patterns: iterators, observers, states, strategies

  Example: Pluggable hashing algorithms (policy mode).

  ````Python
  class StreamHasher():
      """Hash digest generator"""
  
      def __init__(self, alg='md5', size=4096):
          self.size = size
          alg = alg.lower()
          self.hasher = getattr(__import__('hashlib'), alg.lower())()
  
      def __call__(self, stream):
          return self.to_digest(stream)
  
      def to_digest(self, stream):
          """Generate summary in hexadecimal form"""
          for buf in iter(lambda: stream.read(self.size), b''):
              self.hasher.update(buf)
          return self.hasher.hexdigest()
  
  def main():
      """Main function"""
      hasher1 = StreamHasher()
      with open('Python-3.7.6.tgz', 'rb') as stream:
          print(hasher1.to_digest(stream))
      hasher2 = StreamHasher('sha1')
      with open('Python-3.7.6.tgz', 'rb') as stream:
          print(hasher2(stream))
  
  
  if __name__ == '__main__':
      main()
  ````

### Iterators and generators

- An iterator is an object that implements the iterator protocol.

  - There are no keywords in Python like `protocol` or `interface` to define a protocol.
  - Protocols are represented by magic methods in Python.
  - The `__iter__` and `__next__` magic methods are the iterator protocol.

  ````Python
  class Fib(object):
      """Iterator"""
      
      def __init__(self, num):
          self.num = num
          self.a, self.b = 0, 1
          self.idx = 0
     
      def __iter__(self):
          return self
  
      def __next__(self):
          if self.idx < self.num:
              self.a, self.b = self.b, self.a + self.b
              self.idx += 1
              return self.a
          raise StopIteration()
  ````
  
  
- Generators are syntactically simplified iterators.

  ````Python
  def fib(num):
      """Builder"""
      a, b = 0, 1
      for _ in range(num):
          a, b = b, a + b
          yield a
  ````

- Generators evolve into coroutines.

  Generator objects can use the `send()` method to send data, and the sent data becomes the value obtained by the `yield` expression in the generator function. In this way, generators can be used as coroutines, which are simply subroutines that can cooperate with each other.

  ````Python
  def calc_avg():
      """Stream Average"""
      total, counter = 0, 0
      avg_value = None
      while True:
          value = yield avg_value
          total, counter = total + value, counter + 1
          avg_value = total / counter
  
  
  gen = calc_avg()
  next(gen)
  print(gen.send(10))
  print(gen.send(20))
  print(gen.send(30))
  ````

### Concurrent programming

Three options for implementing concurrent programming in Python: multithreading, multiprocessing, and asynchronous I/O. The advantage of concurrent programming is that it can improve the execution efficiency of the program and improve the user experience; the disadvantage is that the concurrent program is not easy to develop and debug, and it is not friendly to other programs.

- Multithreading: Python provides the `Thread` class supplemented by `Lock`, `Condition`, `Event`, `Semaphore` and `Barrier`. There is GIL in Python to prevent multiple threads from executing native bytecodes at the same time. This lock is necessary for CPython, because CPython's memory management is not thread-safe, because the existence of GIL multi-threading cannot take advantage of the multi-core feature of CPU.

  ````Python
  """
  Interview question: What is the difference and connection between process and thread?
  Process - the basic unit of memory allocated by the operating system - a process can contain one or more threads
  Thread - The basic unit by which the operating system allocates CPU
  concurrent programming
  1. Improve execution performance - allow parts of the program that have no causal relationship to execute concurrently
  2. Improve user experience - so that time-consuming operations will not cause the program to freeze
  """
  import glob
  import os
  import threading
  
  from PIL import Image
  
  PREFIX = 'thumbnails'
  
  
  def generate_thumbnail(infile, size, format='PNG'):
      """Generate a thumbnail of the specified image file"""
  file, ext = os.path.splitext(infile)
  file = file[file.rfind('/') + 1:]
  outfile = f'{PREFIX}/{file}_{size[0]}_{size[1]}.{ext}'
  img = Image.open(infile)
  img.thumbnail(size, Image.ANTIALIAS)
  img.save(outfile, format)
  
  
  def main():
      """Main function"""
  if not os.path.exists(PREFIX):
  os.mkdir(PREFIX)
  for infile in glob.glob('images/*.png'):
  for size in (32, 64, 128):
              # Create and start thread
  threading.Thread(
  target=generate_thumbnail,
  args=(infile, (size, size))
  ).start()
  
  
  if __name__ == '__main__':
  main()
  ````

  A situation where multiple threads compete for resources.

  ````Python
  """
  Multithreaded programs are usually simpler to deal with if there are no competing resources
  When multiple threads compete for critical resources, the lack of necessary protections can lead to data corruption
  Description: A critical resource is a resource that is contended by multiple threads
  """
  import time
  import threading
  
  from concurrent.futures import ThreadPoolExecutor
  
  
  class Account(object):
      """Bank Account"""
  
      def __init__(self):
          self.balance = 0.0
          self.lock = threading.Lock()
  
      def deposit(self, money):
          # Protect critical resources with locks
          with self.lock:
              new_balance = self.balance + money
              time.sleep(0.001)
              self.balance = new_balance
  
  
 def main():
      """Main function"""
      account = Account()
      # create thread pool
      pool = ThreadPoolExecutor(max_workers=10)
      futures = []
      for _ in range(100):
          future = pool.submit(account.deposit, 1)
          futures.append(future)
      # close the thread pool
      pool.shutdown()
      for future in futures:
          future.result()
      print(account.balance)
  
  
  if __name__ == '__main__':
      main()
  ````
  
  Modify the above program, start 5 threads to deposit money into the account, 5 threads withdraw money from the account, and pause the thread to wait if the balance is insufficient when withdrawing money. In order to achieve the above goals, it is necessary to schedule the threads for depositing and withdrawing money. When the balance is insufficient, the thread for withdrawing money suspends and releases the lock, while the thread for depositing money should notify the thread for withdrawing money after depositing the money, so that it can change from Suspended state is awakened. Thread scheduling can be implemented using the `Condition` of the `threading` module, which is also created based on locks. The code is as follows:
  
  ````Python
  """
  Multiple threads compete for a resource - protect critical resources - lock (Lock/RLock)
  Multiple threads compete for multiple resources (number of threads > number of resources) - semaphore (Semaphore)
  Scheduling of multiple threads - suspend thread execution / wake up waiting threads - Condition
  """
  from concurrent.futures import ThreadPoolExecutor
  from random import randint
  from time import sleep
  
  import threading
  
  
  class Account:
      """Bank Account"""
  
      def __init__(self, balance=0):
          self.balance = balance
          lock = threading.RLock()
          self.condition = threading.Condition(lock)
  
      def withdraw(self, money):
          """Withdraw money"""
          with self.condition:
              while money > self.balance:
                  self.condition.wait()
              new_balance = self.balance - money
              sleep(0.001)
              self.balance = new_balance
  
      def deposit(self, money):
          """Save money"""
          with self.condition:
              new_balance = self.balance + money
              sleep(0.001)
              self.balance = new_balance
              self.condition.notify_all()
  
  
  def add_money(account):
      while True:
          money = randint(5, 10)
          account.deposit(money)
          print(threading.current_thread().name,
                ':', money, '====>', account.balance)
          sleep(0.5)
  
  
  def sub_money(account):
      while True:
          money = randint(10, 30)
          account.withdraw(money)
          print(threading.current_thread().name,
                ':', money, '<====', account.balance)
          sleep(1)
  
  
  def main():
      account = Account()
      with ThreadPoolExecutor(max_workers=15) as pool:
          for _ in range(5):
              pool.submit(add_money, account)
          for_in range(10):
              pool.submit(sub_money, account)
  
  
  if __name__ == '__main__':
      main()
  ````
  
- Multi-process: Multi-process can effectively solve the problem of GIL. The main class for implementing multi-process is `Process`, and other auxiliary classes are similar to those in the `threading` module. Data sharing between processes can use pipes, sockets, etc. , there is a `Queue` class in the `multiprocessing` module, which provides a queue shared by multiple processes based on the pipe and lock mechanism. Below is an example from the official documentation about multiprocessing and process pools.

````Python
  """
  Use of multiple processes and process pools
  Multithreading cannot play the multi-core feature of CPU due to the existence of GIL
  Multiprocessing should be considered for computationally intensive tasks
  time python3 example22.py
  real 0m11.512s
  user 0m39.319s
  sys 0m0.169s
  The actual execution time after using multi-process is 11.512 seconds, while the user time 39.319 seconds is about 4 times the actual execution time
  This proves that our program uses the multi-core feature of the CPU through multi-process, and this computer is configured with a 4-core CPU
  """
  import concurrent.futures
  import math
  
  PRIMES = [
      1116281,
      1297337,
      104395303,
      472882027,
      533000389,
      817504243,
      982451653,
      112272535095293,
      112582705942171,
      112272535095293,
      115280095190773,
      115797848077099,
      1099726899285419
  ] * 5
  
  
  def is_prime(n):
      """Determine prime numbers"""
      if n % 2 == 0:
          return False
  
      sqrt_n = int(math.floor(math.sqrt(n)))
      for i in range(3, sqrt_n + 1, 2):
          if n % i == 0:
              return False
      return True
  
  
  def main():
      """Main function"""
      with concurrent.futures.ProcessPoolExecutor() as executor:
          for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):
              print('%d is prime: %s' % (number, prime))
  
  
  if __name__ == '__main__':
      main()
  ````

  > **Important**: **Comparison of multithreading and multiprocessing**.
  >
  > Multithreading is required in the following cases:
  >
  > 1. The program needs to maintain a lot of shared state (especially mutable state). Lists, dictionaries, and sets in Python are thread-safe, so the cost of maintaining shared state using threads instead of processes is relatively small.
  > 2. The program will spend a lot of time on I/O operations, there is no need for much parallel computing and it does not need to take up too much memory.
  >
  > Multiprocessing is required in the following cases:
  >
  > 1. The program performs computationally intensive tasks (eg: bytecode manipulation, data processing, scientific computing).
  > 2. The input of the program can be divided into blocks in parallel, and the operation results can be combined.
  > 3. The program does not have any restrictions on memory usage and does not strongly depend on I/O operations (such as reading and writing files, sockets, etc.).

- Asynchronous processing: picking tasks from the scheduler's task queue, the scheduler executes these tasks in an interleaved fashion, we cannot guarantee that the tasks will be executed in a certain order, because the execution order depends on whether a task in the queue is Willingness to give up CPU processing time to another task. Asynchronous tasks are usually implemented by multi-task cooperative processing. Due to the uncertainty of execution time and order, it is necessary to obtain the result of task execution through callback programming or a `future` object. Python 3 supports asynchronous processing through the `asyncio` module and the `await` and `async` keywords (officially listed as keywords in Python 3.7).

  ````Python
  """
  Asynchronous I/O - async / await
  """
  import asyncio
  
  
  def num_generator(m, n):
      """Number generator for the specified range"""
      yield from range(m, n + 1)
  
  
  async def prime_filter(m, n):
      """Prime filter"""
      primes = []
      for i in num_generator(m, n):
          flag = True
          for j in range(2, int(i ** 0.5 + 1)):
              if i % j == 0:
                  flag = False
                  break
          if flag:
              print('Prime =>', i)
              primes.append(i)
  
          await asyncio.sleep(0.001)
      return tuple(primes)
  
  
  async def square_mapper(m, n):
      """Square mapper"""
      squares = []
      for i in num_generator(m, n):
          print('Square =>', i * i)
          squares.append(i * i)
  
          await asyncio.sleep(0.001)
      return squares
  
  
def main():
      """Main function"""
      loop = asyncio.get_event_loop()
      future = asyncio.gather(prime_filter(2, 100), square_mapper(1, 100))
      future.add_done_callback(lambda x: print(x.result()))
      loop.run_until_complete(future)
      loop.close()
  
  
  if __name__ == '__main__':
      main()
  ````

  > **Description**: The above code uses the `get_event_loop` function to get the system default event loop, and the `gather` function to get a `future` object, the `add_done_callback` of the `future` object can add a callback when the execution is completed function, the `run_until_complete` method of the `loop` object can wait for the execution result of the coroutine to be obtained through the `future` object.

  There is a third-party library in Python called `aiohttp`, which provides asynchronous HTTP client and server. This third-party library works with the `asyncio` module and provides support for `Future` objects. `async` and `await` were introduced in Python 3.6 to define functions that execute asynchronously and to create asynchronous contexts, and in Python 3.7 they officially became keywords. The following code asynchronously fetches pages from 5 URLs and extracts the title of the website via named capture groups of regular expressions.

  ````Python
  import asyncio
  import re
  
  import aiohttp
  
  PATTERN = re.compile(r'\<title\>(?P<title>.*)\<\/title\>')
  
  
  async def fetch_page(session, url):
      async with session.get(url, ssl=False) as resp:
          return await resp.text()
  
  
  async def show_title(url):
      async with aiohttp.ClientSession() as session:
          html = await fetch_page(session, url)
          print(PATTERN.search(html).group('title'))
  
  
  def main():
      urls = ('https://www.python.org/',
              'https://git-scm.com/',
              'https://www.jd.com/',
              'https://www.taobao.com/',
              'https://www.douban.com/')
      loop = asyncio.get_event_loop()
      cos = [show_title(url) for url in urls]
      loop.run_until_complete(asyncio.wait(cos))
      loop.close()
  
  
  if __name__ == '__main__':
      main()
  ````

  > **Important**: **Comparison of asynchronous I/O and multi-process**.
  >
  > `asyncio` is a good choice when the program does not need true concurrency or parallelism, but relies more on asynchronous processing and callbacks. If the program has a lot of waiting and sleeping, you should also consider `asyncio`, which is very suitable for writing Web application servers without real-time data processing requirements.

  Python also has many third-party libraries for handling parallel tasks, such as `joblib`, `PyMP`, etc. In actual development, to improve the scalability and concurrency of the system, there are usually two approaches: vertical expansion (increasing the processing power of a single node) and horizontal expansion (turning a single node into multiple nodes). The decoupling of applications can be achieved through message queues. Message queues are equivalent to an extended version of multi-threaded synchronization queues. Applications on different machines are equivalent to threads, and the shared distributed message queue is the Queue in the original program. The most popular and standardized implementation of message queue (message-oriented middleware) is AMQP (Advanced Message Queuing Protocol). AMQP originated from the financial industry and provides functions such as queuing, routing, reliable transmission, security, etc. The most famous implementations include : Apache's ActiveMQ, RabbitMQ, etc.

  To asynchronize tasks, a third-party library called Celery can be used. `Celery` is a distributed task queue written in Python. It uses distributed messages to work and can be based on RabbitMQ or Redis as a back-end message broker.