## Concurrent programming in Python-1

Nowadays, the computers we use are already multi-CPU or multi-core computers, and the operating systems we use basically support "multitasking", which allows us to run multiple programs at the same time, or decompose a program into several relatively Independent subtasks allow multiple subtasks to be executed "parallel" or "concurrently", thereby shortening the execution time of the program and allowing users to obtain a better experience. Therefore, no matter what programming language is used for development, implementing "parallel" or "concurrent" programming has become a standard skill for programmers. In order to describe how to implement "parallel" or "concurrency" in a Python program, we need to understand two important concepts: processes and threads.

### Threads and processes

When we run a program through the operating system, one or more processes will be created. A process is a running activity of a program with certain independent functions on a certain data set. Simply put, a process is the basic unit for the operating system to allocate storage space. Each process has its own address space, data stack, and other auxiliary data used to track the execution of the process; the operating system manages the execution of all processes and provides reasonable for them. resource allocation. A process can create a new process by fork or spawn to perform other tasks, but the new process also has its own independent memory space, so if two processes want to share data, they must be implemented through the inter-process communication mechanism. Methods include pipes, signals, sockets, etc.

A process can also have multiple execution threads. Simply put, it has multiple execution units that can be scheduled by the CPU. This is the so-called thread. Because threads are under the same process, they can share the same context, so it is easier to share and communicate information between threads than processes. Of course, in a single-core CPU system, it is impossible for multiple threads to execute at the same time, because only one thread can obtain the CPU at a certain time, and multiple threads achieve concurrency by sharing the CPU execution time.

The use of multi-threading technology in programs usually brings self-evident benefits. The most important thing is to improve the performance of the program and improve the user experience. Today, almost all the software we use uses multi-threading technology, which can take advantage of the system The built-in process monitoring tool (such as "Activity Monitor" in macOS, "Task Manager" in Windows) to confirm, as shown below.

<img src="https://gitee.com/jackfrued/mypic/raw/master/20210822094243.png" width="80%">

Here, we also need to re-emphasize two concepts with you: **concurrency** (concurrency) and **parallel** (parallel). **Concurrency** usually means that only one instruction can be executed at the same time, but the instructions corresponding to multiple threads are executed in rapid rotation. For example, a processor executes the instructions of thread A for a period of time, then executes the instructions of thread B for a period of time, and then switches back to thread A for a period of time. Due to the extremely fast execution speed and switching speed of the processor, people are completely unaware that the computer has multiple threads switching contexts in this process. In fact, only one thread is executing. **Parallel** means that at the same time, multiple instructions are executed on multiple processors at the same time. Parallelism must depend on multiple processors. Whether macroscopically or microscopically, multiple threads can work together at the same time. implemented. Many times, we do not strictly distinguish between concurrency and parallelism, so we sometimes regard multi-threading, multi-process and asynchronous I/O in Python as means to achieve concurrent programming, but in fact the former two are also Parallel programming is possible, of course there is also the issue of the Global Interpreter Lock (GIL), which we will discuss later.

### Multithreaded programming

The `Thread` class of the `threading` module in the Python standard library can help us implement multi-threaded programming very easily. We use an example of downloading files from the Internet to compare the difference between using multi-threading and not using multi-threading. The code is as follows.

Do not use multithreaded downloads.

````Python
import random
import time


def download(*, filename):
    start = time.time()
    print(f'Start downloading {filename}.')
    time.sleep(random.randint(3, 6))
    print(f'{filename} download complete.')
    end = time.time()
    print(f'Download time: {end - start:.3f} seconds.')


def main():
    start = time.time()
    download(filename='Python from entry to hospital.pdf')
    download(filename='MySQL from deleting the library to running.avi')
    download(filename='Linux from proficient to giving up.mp4')
    end = time.time()
    print(f'Total time: {end - start:.3f} seconds.')


if __name__ == '__main__':
    main()
````

> **Note**: The above code does not really realize the function of network download, but simulates the time overhead required for downloading files by sleeping for a period of time through `time.sleep()`, which is similar to the actual download situation .

Running the above code, you can get the result as shown below. It can be seen that when our program has only one worker thread, each download task needs to wait for the execution of the previous download task before it can start, so the total time spent in program execution is the sum of the respective execution times of the three download tasks.

````
Get started downloading Python from entry to hospital.pdf.
Python from entry to hospitalization.pdf download complete.
Download time: 3.005 seconds.
Start downloading MySQL from deleting the library to running.avi.
MySQL completes the download from deleting the library to running.avi.
Download time: 5.006 seconds.
Start downloading Linux From Mastery to Giving Up.mp4.
Linux went from proficient to giving up .mp3 download complete.
Download time: 6.007 seconds.
Total time: 14.018 seconds.
````

In fact, there is no logical causal relationship between the above three download tasks, the three can be "concurrent", the next download task does not need to wait for the end of the previous download task, for this, we can use multi-threaded programming to rewrite the above code.

````Python
import random
import time
from threading import Thread


def download(*, filename):
    start = time.time()
    print(f'Start downloading {filename}.')
    time.sleep(random.randint(3, 6))
    print(f'{filename} download complete.')
    end = time.time()
    print(f'Download time: {end - start:.3f} seconds.')


def main():
    threads = [
        Thread(target=download, kwargs={'filename': 'Python from entry to hospitalization.pdf'}),
        Thread(target=download, kwargs={'filename': 'MySQL from deleting the library to running.avi'}),
        Thread(target=download, kwargs={'filename': 'Linux from proficient to giving up.mp4'})
    ]
    start = time.time()
    # start three threads
    for thread in threads:
        thread.start()
    # wait for the thread to end
    for thread in threads:
        thread.join()
    end = time.time()
    print(f'Total time: {end - start:.3f} seconds.')


if __name__ == '__main__':
    main()
````

The result of a certain operation is as follows.

````
Start downloading Python from entry to hospital.pdf.
Start downloading MySQL from deleting the library to running.avi.
Start downloading Linux From Mastery to Abandonment.mp4.
MySQL completes the download from deleting the library to running.avi.
Download time: 3.005 seconds.
Python from entry to hospitalization.pdf download complete.
Download time: 5.006 seconds.
Linux from proficient to giving up .mp4 download complete.
Download time: 6.003 seconds.
Total time: 6.004 seconds.
````

From the above running results, it can be found that the execution time of the entire program is almost equal to the execution time of the longest download task, which means that the three download tasks are executed concurrently, and there is no situation where one is waiting for the other. , which obviously improves the execution efficiency of the program. Simply put, if there are very time-consuming execution units in the program, and there is no logical causal relationship between these time-consuming execution units, that is, the execution of unit B does not depend on the execution result of unit A, then A and B Two units can be placed in two different threads, allowing them to execute concurrently. In addition to reducing the waiting time of program execution, the benefits of this can also bring a better user experience, because the blocking of one unit will not cause the "suspended death" of the program, because there are other units in the program that can run.

#### Create thread object using Thread class

As can be seen from the above code, a thread object can be created directly by using the constructor of the `Thread` class, and the `start()` method of the thread object can start a thread. After the thread starts, the function specified by the `target` parameter will be executed, of course, the premise is to obtain the scheduling of the CPU; if the target function to be executed by the thread specified by `target` has parameters, it needs to be specified by the `args` parameter. Parameters, which can be passed in via the `kwargs` parameter. The constructor of the `Thread` class has many other parameters. We will explain it to you when we encounter it. Currently, the ones you need to master are `target`, `args` and `kwargs`.

#### Inheriting the Thread class to customize the thread

In addition to the method of creating threads shown in the above code, you can also customize threads by inheriting the `Thread` class and overriding the `run()` method. The specific code is as follows.

````Python
import random
import time
from threading import Thread


class DownloadThread(Thread):

    def __init__(self, filename):
        self.filename = filename
        super().__init__()

    def run(self):
        start = time.time()
        print(f'Start downloading {self.filename}.')
        time.sleep(random.randint(3, 6))
        print(f'{self.filename} download complete.')
        end = time.time()
        print(f'Download time: {end - start:.3f} seconds.')


def main():
    threads = [
        DownloadThread('Python from entry to hospitalization.pdf'),
        DownloadThread('MySQL from deleting the library to running.avi'),
        DownloadThread('Linux from proficient to giving up.mp4')
    ]
    start = time.time()
    # start three threads
    for thread in threads:
        thread.start()
    # wait for the thread to end
    for thread in threads:
        thread.join()
    end = time.time()
    print(f'Total time: {end - start:.3f} seconds.')


if __name__ == '__main__':
    main()
````

#### Using thread pool

We can also put tasks into multiple threads for execution by means of thread pools. Using threads through thread pools should be the most ideal choice for multi-threaded programming. In fact, the creation and release of threads will bring a large overhead, and frequent creation and release of threads is usually not a good choice. Using the thread pool, you can prepare several threads in advance. You do not need to create and release threads through custom code during use, but directly reuse the threads in the thread pool. Python's built-in `concurrent.futures` module provides support for thread pools, the code is shown below.

````Python
import random
import time
from concurrent.futures import ThreadPoolExecutor
from threading import Thread


def download(*, filename):
    start = time.time()
    print(f'Start downloading {filename}.')
    time.sleep(random.randint(3, 6))
    print(f'{filename} download complete.')
    end = time.time()
    print(f'Download time: {end - start:.3f} seconds.')


def main():
    with ThreadPoolExecutor(max_workers=4) as pool:
        filenames = ['Python from entry to hospital.pdf', 'MySQL from deleting libraries to running.avi', 'Linux from proficient to giving up.mp4']
        start = time.time()
        for filename in filenames:
            pool.submit(download, filename=filename)
    end = time.time()
    print(f'Total time: {end - start:.3f} seconds.')


if __name__ == '__main__':
    main()
````

### Daemon thread

The so-called "daemon thread" is an execution thread that is no longer worth keeping when the main thread ends. Unworthy of retention here means that the daemon thread will be destroyed after all other non-daemon threads run, and it guards all non-daemon threads in the current process. Simply put, the daemon thread will hang up with the main thread, and the life cycle of the main thread is the life cycle of a process. If you don't understand, we can look at a simple code.

````Python
import time
from threading import Thread


def display(content):
    while True:
        print(content, end='', flush=True)
        time.sleep(0.1)


def main():
    Thread(target=display, args=('Ping', )).start()
    Thread(target=display, args=('Pong', )).start()


if __name__ == '__main__':
    main()
````

> **Note**: In the above code, we set the parameter `flush` of the `print` function to `True`, this is because the value of the `flush` parameter is `False`, but `print` does not Doing newline processing will cause the output of `print` to be put into the output buffer of the operating system each time, until the buffer is filled with the output content, and the buffer will be emptied to generate an output. The above phenomenon is a setting made by the operating system in order to reduce I/O interrupts and improve CPU utilization. In order to make the code interact intuitively, we set the `flush` parameter to `True` to force the output buffer to be emptied for each output. Area.

The above code will not stop after running, because there are infinite loops in both child threads, unless you manually interrupt the execution of the code. However, if the parameter named `daemon` is set to `True` when creating the thread object, the two threads become daemon threads, then when the other threads end, even if there is an infinite loop, the two daemon threads It will also hang and will not continue to execute. The code is as follows.

 ````Python
 import time
 from threading import Thread
 
 
 def display(content):
     while True:
         print(content, end='', flush=True)
         time.sleep(0.1)
 
 
 def main():
     Thread(target=display, args=('Ping', ), daemon=True).start()
     Thread(target=display, args=('Pong', ), daemon=True).start()
     time.sleep(5)
 
 
 if __name__ == '__main__':
     main()
 ````

In the above code, we add a line `time.sleep(5)` to the main thread to let the main thread sleep for 5 seconds. During this process, the daemon thread that outputs `Ping` and `Pong` will continue to run until the main thread At the end of 5 seconds, the two daemon threads are also destroyed and no longer continue to run.

> **Thinking**: If the `daemon=True` in line 12 of the above code is removed, how will the code execute? Interested readers can try it out and see if the actual implementation results in what you imagined.

### Resource competition

When writing multithreaded code, it is inevitable to encounter multiple threads competing for the same resource (object). In this case, if there is no reasonable mechanism to protect the contested resources, unexpected situations may occur. The following code creates `100` threads to transfer money to the same bank account (with an initial balance of `0` yuan), and each thread transfers an amount of `1` yuan. Under normal circumstances, the final balance of our bank account should be `100` yuan, but we cannot get the result of `100` yuan by running the following code.

````Python
import time

from concurrent.futures import ThreadPoolExecutor


class Account(object):
    """Bank Account"""

    def __init__(self):
        self.balance = 0.0

    def deposit(self, money):
        """Save money"""
        new_balance = self.balance + money
        time.sleep(0.01)
        self.balance = new_balance


def main():
    """Main function"""
    account = Account()
    with ThreadPoolExecutor(max_workers=16) as pool:
        for _ in range(100):
            pool.submit(account.deposit, 1)
    print(account.balance)


if __name__ == '__main__':
    main()
````

The `Account` class in the above code represents a bank account, its `deposit` method represents the deposit behavior, and the parameter `money` represents the amount deposited. We started `100` threads to transfer money to an account through the thread pool, but the above code can't run the `100` we expected result, which is when multiple threads compete for a resource, it may encounter The problem of data inconsistency. Pay attention to the `14` line of the above code, when multiple threads execute this line of code, they will perform the operation of adding the deposit amount on the same balance, which will cause the "lost update" phenomenon, that is, before The results of modifying the data are overwritten by subsequent modifications, so the correct results cannot be obtained.

To solve the above problems, the lock mechanism can be used to protect the key code that operates the data through the lock. The `threading` module of the Python standard library provides the `Lock` and `RLock` classes to support the locking mechanism. Next, we add a lock object to the bank account, and use the lock object to solve the problem of "lost update" when depositing just now. The code is as follows.

````Python
import time

from concurrent.futures import ThreadPoolExecutor
from threading import RLock


class Account(object):
    """Bank Account"""

    def __init__(self):
        self.balance = 0.0
        self.lock = RLock()

    def deposit(self, money):
        # get the lock
        self.lock.acquire()
        try:
            new_balance = self.balance + money
            time.sleep(0.01)
            self.balance = new_balance
        finally:
            # release lock
            self.lock.release()


def main():
    """Main function"""
    account = Account()
    with ThreadPoolExecutor(max_workers=16) as pool:
        for _ in range(100):
            pool.submit(account.deposit, 1)
    print(account.balance)


if __name__ == '__main__':
    main()
````

In the above code, the operations of acquiring and releasing locks can also be implemented through contextual syntax. Using contextual syntax will make the code simpler and more elegant, which is also the way we recommend everyone to use.

````Python
import time

from concurrent.futures import ThreadPoolExecutor
from threading import RLock


class Account(object):
    """Bank Account"""

    def __init__(self):
        self.balance = 0.0
        self.lock = RLock()

    def deposit(self, money):
        # Acquire and release locks via context syntax
        with self.lock:
            new_balance = self.balance + money
            time.sleep(0.01)
            self.balance = new_balance


def main():
    """Main function"""
    account = Account()
    with ThreadPoolExecutor(max_workers=16) as pool:
        for _ in range(100):
            pool.submit(account.deposit, 1)
    print(account.balance)


if __name__ == '__main__':
    main()
````

> **Thinking**: Modify the above code to 5 threads to deposit money to the bank account, 5 threads to withdraw money from the bank account, the thread to withdraw money needs to stop and wait for the thread to deposit money when the balance of the bank account is insufficient Try to withdraw money after depositing it. The knowledge of thread scheduling is required here. You can study the `Condition` class in the `threading` module by yourself to see if this task can be completed.

### GIL problem

If we use the official Python interpreter (usually called CPython) to run Python programs, we cannot increase the CPU utilization to nearly 400% (for a 4-core CPU) or 800% (for an 8-core CPU) by using multithreading Core CPU), because CPython is limited by the GIL (Global Interpreter Lock) when executing code. Specifically, when CPython executes any code, the corresponding thread needs to obtain the GIL first, and then every 100 (bytecode) instructions are executed, CPython will let the thread that obtained the GIL actively release the GIL, so that other threads can opportunity to execute. Because of the GIL, no matter how many cores your CPU has, the Python code we write has no chance to actually execute in parallel.

GIL is a historical legacy of the design of the official Python interpreter. To solve this problem and allow multi-threading to take advantage of the multi-core CPU, it is necessary to re-implement a Python interpreter without GIL. According to the official statement, this problem will be solved when Python 4.0 is released, let us wait and see. At present, for CPython, if you want to give full play to the multi-core advantages of the CPU, you can consider using multi-process, because each process corresponds to a Python interpreter, so each process has its own independent GIL, which can break through the GIL. limit. In the next chapter, we will introduce you to the relevant knowledge about multiprocessing, and compare the code and execution effect of multithreading and multiprocessing.