## Concurrent programming in Python-3

Crawlers are typical I/O-intensive tasks. The characteristic of I/O-intensive tasks is that the program will often enter the blocking state due to I/O operations. For example, we used `requests` to get page code or binary content before, and send After a request, the program must wait for the website to return a response before it can continue to run. If the target website is not very powerful or the network condition is not very good, the waiting time for the response may be long, and the whole program is always blocked in this process. , did nothing. Through the previous courses, we already know that we can speed up the crawler through multi-threading. The essence of using multi-threading is that when one thread is blocked, the program has other threads that can continue to run, so the whole program will not run in A lot of time is wasted blocking and waiting.

In fact, there is another way of concurrent programming that is very suitable for I/O intensive tasks, we call it asynchronous programming, you can also call it asynchronous I/O. This method does not need to start multiple threads or multiple processes to achieve concurrency. It improves CPU utilization through the cooperation of multiple subroutines, which solves the problem of low CPU utilization for I/O-intensive tasks. , I generally refer to this approach as "cooperative concurrency". Here, I am not going to discuss the various I/O modes of the operating system, because this is too abstract for many readers; but we must first throw two sets of concepts for you, one is called "blocking" and "non-blocking". ", a group called "synchronous" and "asynchronous".

### basic concept

#### blocking

The blocking state refers to the state in which the program is suspended when the required computing resources are not obtained. A program is said to be blocked on an operation when it cannot continue processing other things while waiting for an operation to complete. Blocking may occur at any time, the most typical ones are I/O interrupts (including network I/O, disk I/O, user input, etc.), sleep operations, waiting for a thread to finish execution, and even when the CPU switches contexts, the program Can't really execute, this is the so-called blocking.

#### non-blocking

A program is not blocked in the process of waiting for an operation and can continue to process other things, then the program is said to be non-blocking in that operation. Non-blocking does not exist at any program level and under any circumstances. A program's non-blocking state is only possible if its level of encapsulation can encompass independent subprogram units. Obviously, the blocking of an operation can lead to time-consuming and inefficient programs, so we will want to make it non-blocking.

#### Synchronize

In order to complete a certain task, different program units need to rely on a certain communication method to coordinate in the execution process. We call these program units synchronously executed. For example, in the operation of depositing money in a bank account mentioned above, we use "lock" as a communication signal in the code, so that multiple deposit operations are forced to be queued and executed in sequence, which is called synchronization.

#### async

Different program units can complete a task without communication and coordination during the execution process. This method is called asynchronous. For example, when using a crawler to download a page, after the scheduler invokes the downloader, other tasks can be scheduled without the need to maintain communication with the downloader to coordinate behavior. Operations such as downloading and saving of different web pages are irrelevant, and there is no need for mutual notification and coordination. Obviously, the completion time and sequence of asynchronous operations cannot be determined.

Many people are not able to accurately grasp these concepts, here we briefly summarize, the focus of synchronization and asynchrony is **message communication mechanism**, and the final expression is "order" and "disorder" The difference between blocking and non-blocking is the state of the program while waiting for a message, and the final expression is whether the program can do something else while waiting. If you want to understand these contents in depth, I recommend everyone to read the classic book ["UNIX Network Programming"](https://item.jd.com/11880047.html), this book is very good.

### Generators and coroutines

As we said earlier, asynchronous programming is a kind of "cooperative concurrency", that is, through the cooperation of multiple subprograms, the utilization of the CPU is improved, thereby reducing the time wasted by the program in blocking and waiting, and finally achieves the effect of concurrency. We can call multiple subroutines that cooperate with each other as "coroutines", which are the key to implementing asynchronous programming. Before introducing coroutines, let's go through the following code to see what a generator is.

````Python
def fib(max_count):
    a, b = 0, 1
    for _ in range(max_count):
        a, b = b, a + b
        yield a
````

Above we have written a generator that generates Fibonacci series. Calling the above `fib` function is not to execute the function to get the return value, because there is a special keyword `yield` in the `fib` function. This keyword makes the `fib` function somewhat different from the normal function, calling the function will get a generator object, we can verify this with the following code.

````Python
gen_obj = fib(20)
print(gen_obj)
````

output:

````
<generator object fib at 0x106daee40>
````

We can use the built-in function `next` to get the value of the Fibonacci sequence from the generator object, or we can iterate over the values ​​that the generator can provide through a `for-in` loop, as shown in the code below.

````Python
for value in gen_obj:
    print(value)
````

The generator is pre-activated, it is a coroutine, it can cooperate with other subroutines.

````Python
def calc_average():
    total, counter = 0, 0
    avg_value = None
    while True:
        curr_value = yield avg_value
        total += curr_value
        counter += 1
        avg_value = total / counter


def main():
    obj = calc_average()
    # generator pre-activation
    obj.send(None)
    for _ in range(5):
        print(obj.send(float(input())))


if __name__ == '__main__':
    main()
````

The above `main` function first activates it as a coroutine by sending a `None` value through the `send` method of the generator object, or `next(obj)` to achieve the same effect. Next, the coroutine object will receive the data sent by the `main` function and produce (`yield`) the average of the data. Through the above example, I don't know if you can see how the two subroutines "collaborate".

### async function

In Python 3.5, two very interesting elements were introduced, one called `async` and one called `await`, which became official keywords in Python 3.7. Through these two keywords, the writing of coroutine code can be simplified, and multiple subroutines can be well coordinated in a simpler way. We use an example to illustrate, please take a look at the code below.

````Python
import time


def display(num):
    time.sleep(1)
    print(num)
	


def main():
    start = time.time()
    for i in range(1, 10):
        display(i)
    end = time.time()
    print(f'{end - start:.3f}seconds')


if __name__ == '__main__':
    main()
````

The above code will output the numbers from `1` to `9` in turn each time it is executed. Each interval is `1` seconds. It takes about `9` seconds to execute the entire code. I believe everyone can see this. Understand. I don’t know if you realize that this code is executed in a synchronous and blocking manner. Synchronization can be seen from the output of the code, and blocking means that when the `display` function is called to sleep, other parts of the entire code cannot To continue execution, you must wait for the sleep to end.

Next, we try to rewrite the above code in an asynchronous way, so that the `display` function works asynchronously.

````Python
import asyncio
import time


async def display(num):
    await asyncio.sleep(1)
    print(num)


def main():
    start = time.time()
    objs = [display(i) for i in range(1, 10)]
    loop = asyncio.get_event_loop()
    loop.run_until_complete(asyncio.wait(objs))
    loop.close()
    end = time.time()
    print(f'{end - start:.3f}seconds')


if __name__ == '__main__':
    main()
````

The `asyncio` module in Python provides support for asynchronous I/O. In the above code, we first add the `async` keyword in front of the `display` function to make it an asynchronous function. Calling the asynchronous function does not execute the function body but obtains a coroutine object. We changed the `time.sleep(1)` in the `display` function to `await asyncio.sleep(1)`, the difference between the two is that the latter does not block the entire code, because the `await` operation will Give other cooperating subroutines a chance to run on CPU resources. In order for these subroutines to cooperate, we need to put them on an event loop (a system that implements message dispatch and delivery), because when the coroutine encounters I/O operation blocking, it will go to the event loop to listen for I Whether the /O operation is completed, and register its own context and its own wake-up function (to resume execution), then the coroutine becomes blocked**. The 12th line of code above creates `9` coroutine objects and puts them in a list, the 13th line of code obtains the system event loop through the `get_event_loop` function of the `asyncio` module, and the 14th line through `asyncio` The module's `run_until_complete` function mounts the coroutine object on the event loop. Executing the above code will find that the `9` coroutines that will block `1` seconds respectively only block for about `1` seconds in total, because the blocked coroutine object will give up the possession of the CPU and Instead of leaving the CPU in an idle state, this method greatly improves the utilization of the CPU**. And we'll also notice that the numbers are not printed in the order from `1` to `9`, which is exactly what we want, indicating that they are executed asynchronously. For I/O-intensive tasks such as crawlers, this cooperative concurrency is in many cases a better choice than using multithreading, because it reduces the need to manage and maintain multiple threads and multiple thread switching. costs incurred.

### aiohttp library

The `requests` third-party library we used before does not support asynchronous I/O. If you want to use asynchronous I/O to speed up the execution of crawler code, we can install and use a third-party library named `aiohttp`.

Install `aiohttp`.

````Bash
pip install aiohttp
````

The code below uses `aiohttp` to grab the home pages of `10` websites and parse out their titles.

````Python
import asyncio
import re

import aiohttp
from aiohttp import ClientSession

TITLE_PATTERN = re.compile(r'<title.*?>(.*?)</title>', re.DOTALL)


async def fetch_page_title(url):
    async with aiohttp.ClientSession(headers={
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36',
    }) as session: # type: ClientSession
        async with session.get(url, ssl=False) as resp:
            if resp.status == 200:
                html_code = await resp.text()
                matcher = TITLE_PATTERN.search(html_code)
                title = matcher.group(1).strip()
                print(title)


def main():
    urls = [
        'https://www.python.org/',
        'https://www.jd.com/',
        'https://www.baidu.com/',
        'https://www.taobao.com/',
        'https://git-scm.com/',
        'https://www.sohu.com/',
        'https://gitee.com/',
        'https://www.amazon.com/',
        'https://www.usa.gov/',
        'https://www.nasa.gov/'
    ]
    objs = [fetch_page_title(url) for url in urls]
    loop = asyncio.get_event_loop()
    loop.run_until_complete(asyncio.wait(objs))
    loop.close()


if __name__ == '__main__':
    main()
````

output:

````
Jingdong (JD.COM) - Genuine low price, quality assurance, timely delivery, easy shopping!
sohu
Taobao - Amoy! I like
Baidu, you will know
Gitee - Git-based code hosting and R&D collaboration platform
Git
NASA
Official Guide to Government Information and Services &#124; USAGov
Amazon.com. Spend less. Smile more.
Welcome to Python.org
````

As you can see from the output above, the output order of website homepage titles has nothing to do with the order in which their URLs are in the list. Lines 11 to 13 of the code create a `ClientSession` object, through its `get` method, you can initiate a request to the specified URL, as shown in line 14, there is no `Session` object in `requests` The essential difference, the only difference is that the asynchronous context is used here. The `await` on line 16 causes the subroutine blocked by the I/O operation to give up the CPU usage, which allows other subroutines to run to grab the page. Lines 17 and 18 of the code use the regular expression capture group operation to parse the page title. `fetch_page_title` is an asynchronous function decorated with the `async` keyword, calling this function will get the coroutine object, as shown in line 35 of the code. The code behind is no different from the previous example, I believe everyone can understand.

You can try to change `aiohttp` back to `requests` to see what is the difference between the above code and the above code without using asynchronous I/O or multi-threading. I believe that through this comparison, you can understand us more deeply Several concepts emphasized before: synchronous and asynchronous, blocking and non-blocking.