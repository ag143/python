## Using Selenium to scrape dynamic content of web pages

According to the Global Internet Accessibility Audit Report released by the authoritative organization, about three-quarters of the world's websites have their content or part of the content dynamically generated through JavaScript, which means that when "viewing the source code of a web page" in a browser window These can't be found in the HTML code, which means the way we used to scrape the data doesn't work. There are basically two solutions to solve such a problem. One is to obtain a data interface that provides dynamic content, which is also suitable for capturing data from mobile apps; the other is to run the browser through the automated testing tool Selenium to obtain the rendered data. dynamic content. For the first solution, we can use the browser's "developer tools" or more professional packet capture tools (such as Charles, Fiddler, Wireshark, etc.) to obtain the data interface, and the subsequent operations are explained in the previous chapter. The data obtained from the "360 Pictures" website is the same, and we will not repeat them here. In this chapter, we focus on how to use the automated testing tool Selenium to obtain dynamic content of a website.

### Introduction to Selenium

Selenium is an automated testing tool that can be used to drive browsers to perform specific behaviors, ultimately helping crawler developers to obtain dynamic content of web pages. Simply put, as long as we can see the content in the browser window, we can use Selenium to get it. For those websites that use JavaScript dynamic rendering technology, Selenium will be an important choice. Below, we still take the Chrome browser as an example to explain the usage of Selenium. You need to install the Chrome browser and download its driver first. The Chrome browser driver can be downloaded from the [ChromeDriver official website](https://chromedriver.chromium.org/downloads). The driver version should correspond to the browser version. If there is no completely corresponding version, select the version code. the closest version.

<img src="https://gitee.com/jackfrued/mypic/raw/master/20220310134558.png" style="zoom: 35%">

### Using Selenium

We can first install Selenium through `pip`, the command is as follows.

```Shell
pip install selenium
````

#### Loading the page

Next, we use the following code to drive the Chrome browser to open Baidu.

````Python
from selenium import webdriver

# Create Chrome browser object
browser = webdriver.Chrome()
# Load the specified page
browser.get('https://www.baidu.com/')
````

If you don't want to use the Chrome browser, you can also modify the above code to control other browsers, just create the corresponding browser objects (such as Firefox, Safari, etc.). Run the above program, if you see the error message shown below, it means that we have not added the Chrome browser driver to the PATH environment variable, nor have we specified the location of the Chrome browser driver in the program.

```Shell
selenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home
````

There are three ways to solve this problem:

1. Put the downloaded ChromeDriver in the existing PATH environment variable. It is recommended to put it directly in the same directory as the Python interpreter, because we have put the path of the Python interpreter into the PATH environment variable when installing Python before.

2. Put ChromeDriver in the `bin` folder in the project virtual environment (the corresponding directory for Windows system is `Scripts`), so that ChromeDriver is in the same location as the Python interpreter in the virtual environment, and it can definitely be found .

3. Modify the above code, when creating the Chrome object, configure the `Service` object through the `service` parameter, and specify the location of the ChromeDriver through the `executable_path` parameter of the `Service` object, as shown below:

    ````Python
    from selenium import webdriver
    from selenium.webdriver.chrome.service import Service
    
    browser = webdriver.Chrome(service=Service(executable_path='venv/bin/chromedriver'))
    browser.get('https://www.baidu.com/')
    ````

#### Find elements and simulate user behavior

Next, we can try to simulate a user entering a search keyword in the text box on the Baidu homepage and clicking the "Baidu click" button. After the page is loaded, you can get page elements through the `find_element` and `find_elements` methods of the `Chrome` object. Selenium supports a variety of ways to get elements, including: CSS selector, XPath, element name (tag name), Element ID, class name, etc. The former can get a single page element (`WebElement` object), and the latter can get a list of multiple page elements. After obtaining the `WebElement` object, you can use `send_keys` to simulate user input behavior, and `click` to simulate user click operations. The code is as follows.

````Python
from selenium import webdriver
from selenium.webdriver.common.by import By

browser = webdriver.Chrome()
browser.get('https://www.baidu.com/')
# Get element by element ID
kw_input = browser.find_element(By.ID, 'kw')
# Simulate user input behavior
kw_input.send_keys('Python')
# Get element by CSS selector
su_button = browser.find_element(By.CSS_SELECTOR, '#su')
# Simulate user click behavior
su_button.click()
````

If you want to perform a series of actions, such as simulating drag and drop operations, you can create an `ActionChains` object, and interested readers can study it by themselves.

#### Implicit wait and explicit wait

There is one more detail here that you need to know. The elements on the web page may be dynamically generated. When we use the `find_element` or `find_elements` method to obtain, the rendering may not be completed, and a `NoSuchElementException` error will be thrown. In order to solve this problem, we can use the implicit waiting method to let the browser complete the rendering of page elements by setting the waiting time. In addition, we can also use display waiting. By creating a `WebDriverWait` object, and setting the waiting time and conditions, when the conditions are not met, we can wait and then try to perform subsequent operations. The specific code is as follows.

````Python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions
from selenium.webdriver.support.wait import WebDriverWait

browser = webdriver.Chrome()
# Set the browser window size
browser.set_window_size(1200, 800)
browser.get('https://www.baidu.com/')
# Set the implicit wait time to 10 seconds
browser.implicitly_wait(10)
kw_input = browser.find_element(By.ID, 'kw')
kw_input.send_keys('Python')
su_button = browser.find_element(By.CSS_SELECTOR, '#su')
su_button.click()
# Create display wait object
wait_obj = WebDriverWait(browser, 10)
# Set the waiting condition (wait for the div of the search result to appear)
wait_obj.until(
    expected_conditions.presence_of_element_located(
        (By.CSS_SELECTOR, '#content_left')
    )
)
# screenshot
browser.get_screenshot_as_file('python_result.png')
````


The wait condition `presence_of_element_located` set above means to wait for the specified element to appear. The following table lists the commonly used wait conditions and their meanings.

| Waiting Conditions | Specific Meanings |
| ---------------------------------------- | -------- ----------------------------- |
| `title_is / title_contains` | The title is the specified content / The title contains the specified content |
| `visibility_of` | element is visible |
| `presence_of_element_located` | The positioned element is loaded |
| `visibility_of_element_located` | The positioned element becomes visible |
| `invisibility_of_element_located` | The positioned element becomes invisible |
| `presence_of_all_elements_located` | All located elements are loaded |
| `text_to_be_present_in_element` | The element contains the specified content |
| `text_to_be_present_in_element_value` | The element's `value` attribute contains the specified content |
| `frame_to_be_available_and_switch_to_it` | Load and switch to the specified inner window |
| `element_to_be_clickable` | Element is clickable |
| `element_to_be_selected` | element is selected |
| `element_located_to_be_selected` | The positioned element is selected |
| `alert_is_present` | Alert popup window appears |

#### Execute JavaScript code

For pages that use waterfall loading, if you want to load more content in the browser window, you can execute JavaScript code through the `execute_scripts` method of the browser object. For some advanced crawling operations, similar operations are likely to be used. If your crawler code requires JavaScript support, it is recommended to have a proper understanding of JavaScript, especially BOM and DOM operations in JavaScript. We add the following code before the screenshot in the above code, so that we can use JavaScript to scroll the page to the bottom.

````Python
# Execute JavaScript code
browser.execute_script('document.documentElement.scrollTop = document.documentElement.scrollHeight')
````

#### Selenium anti-climbing crack

Some websites have set up anti-crawling measures specifically for Selenium, because using Selenium-driven browsers, you can see in the console that the `webdriver` property value is `true`, if you want to bypass this check, you can go to Before loading the page, modify it to `undefined` by executing JavaScript code.

<img src="https://gitee.com/jackfrued/mypic/raw/master/20220310154246.png" style="zoom:50%">

On the other hand, we can also hide the "Chrome is being controlled by automated testing software" on the browser window, the complete code is shown below.

````Python
# Create Chrome parameter object
options = webdriver.ChromeOptions()
# add experimental parameters
options.add_experimental_option('excludeSwitches', ['enable-automation'])
options.add_experimental_option('useAutomationExtension', False)
# Create Chrome browser object and pass in parameters
browser = webdriver.Chrome(options=options)
# Execute Chrome Developer Protocol commands (execute the specified JavaScript code when the page is loaded)
browser.execute_cdp_cmd(
    'Page.addScriptToEvaluateOnNewDocument',
    {'source': 'Object.defineProperty(navigator, "webdriver", {get: () => undefined})'}
)
browser.set_window_size(1200, 800)
browser.get('https://www.baidu.com/')
````

#### headless browser

Many times, we do not need to see the browser window when crawling data. As long as there is a Chrome browser and the corresponding driver, our crawler can run. If you don't want to see the browser window, we can set up a headless browser in the following way.

````Python
options = webdriver.ChromeOptions()
options.add_argument('--headless')
browser = webdriver.Chrome(options=options)
````

### API Reference

There is still a lot of knowledge related to Selenium, we will not go into details here. The following is a list of some commonly used properties and methods of browser objects and `WebElement` objects. For specific content, you can also refer to Selenium [Chinese translation of official documents](https://selenium-python-zh.readthedocs.io/en/latest/index.html).

#### browser object

Table 1. Common properties

| property name | description |
| ----------------------- | ------------------------- ------- |
| `current_url` | URL of the current page |
| `current_window_handle` | The handle (reference) of the current window |
| `name` | The name of the browser |
| `orientation` | current device orientation (landscape, portrait) |
| `page_source` | The source code of the current page (including dynamic content) |
| `title` | The title of the current page |
| `window_handles` | Handles of all windows opened by the browser |

Table 2. Common methods

| method name | description |
| -------------------------------------- | ---------- ------------------------- |
| `back` / `forward` | Back/forward in browsing history |
| `close` / `quit` | Close the current browser window / quit the browser instance |
| `get` | Loads the page at the specified URL into the browser |
| `maximize_window` | Maximize the browser window |
| `refresh` | Refresh the current page |
| `set_page_load_timeout` | Set page load timeout |
| `set_script_timeout` | Set JavaScript execution timeout |
| `implicit_wait` | Set wait for element to be found or target instruction to complete |
| `get_cookie` / `get_cookies` | Get the specified cookie / Get all cookies |
| `add_cookie` | Add cookie information |
| `delete_cookie` / `delete_all_cookies` | delete the specified cookie / delete all cookies |
| `find_element` / `find_elements` | Find a single element / Find a range of elements |


#### WebElement objects

Table 1. WebElement common properties

| property name | description |
| ---------- | -------------- |
| `location` | The location of the element |
| `size` | the size of the element |
| `text` | The text content of the element |
| `id` | ID of the element |
| `tag_name` | element's tag name |

Table 2. Common methods

| method name | description |
| -------------------------------- | ---------------- -------------------- |
| `clear` | Clear the contents of a text box or text field |
| `click` | Click on an element |
| `get_attribute` | Get the attribute value of an element |
| `is_displayed` | Determines whether the element is visible to the user |
| `is_enabled` | Determine if the element is enabled |
| `is_selected` | Determines whether an element (radio box and checkbox) is selected |
| `send_keys` | Simulate input text |
| `submit` | Submit form |
| `value_of_css_property` | Get the specified CSS property value |
| `find_element` / `find_elements` | Get a single child element / Get a range of child elements |
| `screenshot` | Take a snapshot of an element |

### Simple case

The following example demonstrates how to use Selenium to search and download images from the "360 Images" website.

````Python
import os
import time
from concurrent.futures import ThreadPoolExecutor

import requests
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys

DOWNLOAD_PATH = 'images/'


def download_picture(picture_url: str):
    """
    download save image
    :param picture_url: URL of the picture
    """
    filename = picture_url[picture_url.rfind('/') + 1:]
    resp = requests.get(picture_url)
    with open(os.path.join(DOWNLOAD_PATH, filename), 'wb') as file:
        file.write(resp.content)


if not os.path.exists(DOWNLOAD_PATH):
    os.makedirs(DOWNLOAD_PATH)
browser = webdriver.Chrome()
browser.get('https://image.so.com/z?ch=beauty')
browser.implicitly_wait(10)
kw_input = browser.find_element(By.CSS_SELECTOR, 'input[name=q]')
kw_input.send_keys('Teacher Cang')
kw_input.send_keys(Keys.ENTER)
for_in range(10):
    browser.execute_script(
        'document.documentElement.scrollTop = document.documentElement.scrollHeight'
    )
    time.sleep(1)
imgs = browser.find_elements(By.CSS_SELECTOR, 'div.waterfall img')
with ThreadPoolExecutor(max_workers=32) as pool:
    for img in imgs:
        pic_url = img.get_attribute('src')
        pool.submit(download_picture, pic_url)
````

Run the above code to check whether the images searched by keywords are downloaded in the specified directory.