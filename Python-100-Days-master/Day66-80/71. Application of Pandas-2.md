## Pandas application-2

### Application of DataFrame

#### Create DataFrame object

##### Create `DataFrame` object from 2D array

Code:

````Python
scores = np.random.randint(60, 101, (5, 3))
courses = ['Chinese', 'Math', 'English']
ids = [1001, 1002, 1003, 1004, 1005]
df1 = pd.DataFrame(data=scores, columns=courses, index=ids)
df1
````

output:

````
Chinese Mathematics English
1001 69 80 79
1002 71 60 100
1003 94 81 93
1004 88 88 67
1005 82 66 60
````

##### Create `DataFrame` object from dictionary

Code:

````Python
scores = {
    'language': [62, 72, 93, 88, 93],
    'math': [95, 65, 86, 66, 87],
    'English': [66, 75, 82, 69, 82],
}
ids = [1001, 1002, 1003, 1004, 1005]
df2 = pd.DataFrame(data=scores, index=ids)
df2
````

output:

````
Chinese Mathematics English
1001 69 80 79
1002 71 60 100
1003 94 81 93
1004 88 88 67
1005 82 66 60
````

##### Read CSV file to create `DataFrame` object

You can read CSV files through the `read_csv` function of the `pandas` module. The `read_csv` function has many parameters. The following accepts several more important parameters.

- `sep` / `delimiter`: delimiter, the default is `,`.
- `header`: The position of the table header (column index), the default value is `infer`, and the content of the first row is used as the table header (column index).
- `index_col`: Column used as row index (label).
- `usecols`: Columns to be loaded, either serial number or column name can be used.
- `true_values`/`false_values`: which values ​​are treated as boolean `True`/`False`.
- `skiprows`: Specify the lines to skip by line number, index or function.
- `skipfooter`: The number of trailing lines to skip.
- `nrows`: The number of rows to read.
- `na_values`: which values ​​are treated as nulls.

Code:

````Python
df3 = pd.read_csv('2018 Beijing Points Settlement Data.csv', index_col='id')
df3
````

output:

````
     name birthday company score
id
1 Yang x 1972-12 Beijing Lide xxxx 122.59
2nd x 1974-12 Beijing Aerospace xxxx 121.25
3 Wang x 1974-05 Brand Alliance xxxx 118.96
4 Yang x 1975-07 Zhongke Patent xxxx 118.21
5 sheets x 1974-11 Beijing Ali xxxx 117.79
... ... ... ...
6015 Sun x 1978-08 Huawei Ocean xxxx 90.75
6016 Liu x 1976-11 Flowserve Fluid xxxx 90.75
Week 6017 x 1977-10 Evonik Deguxxxx 90.75
6018 Zhao x 1979-07 Australia Cochlear xxxx 90.75
6019 He x 1981-06 Beijing Procter & Gamble xxxx 90.75
6019 rows × 4 columns
````


> **Note**: If you need the CSV file in the above example, you can get it through the Baidu cloud disk address below. The data is in the "Learn Data Analysis from Scratch" directory. Link: https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g, extraction code: e7b4.

##### Read Excel file to create `DataFrame` object

Excel files can be read through the `read_excel` function of the `pandas` module. This function is very similar to the `read_csv` above, with an additional `sheet_name` parameter to specify the name of the data sheet, but unlike the CSV file, there is no Arguments like `sep` or `delimiter`. In the following code, the `skiprows` parameter of the `read_excel` function is a Lambda function, through which it is specified to read only the header of the Excel file and 10% of the data, and skip other data.

Code:

````Python
import random

df4 = pd.read_excel(
    io='Sales data of Xiaobaojian Pharmacy in 2018.xlsx',
    usecols=['Drug purchase time', 'Social security card number', 'Commodity name', 'Sales quantity', 'Amount receivable', 'Amount received'],
    skiprows=lambda x: x > 0 and random.random() > 0.1
)
df4
````

> **Note**: If you need the Excel file in the above example, you can get it through the Baidu cloud disk address below. The data is in the "Learn Data Analysis from Scratch" directory. Link: https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g, extraction code: e7b4.

output:

````
    Time of purchase Social security card number Commodity name Sales quantity Receivable amount Amount received
0 2018-03-23 ​​Wednesday 10012157328 Strong xx 1 13.8 13.80
1 2018-07-12 Tuesday 108207828 Strong xx 1 13.8 13.80
2 2018-01-17 Sunday 13358228 Qingre xx liquid 1 28.0 28.00
3 2018-07-11 Monday 10031402228 Sanjiu xx Ling 5 149.0 130.00
4 2018-01-20 Wednesday 10013340328 Sanjiu xx Ling 3 84.0 73.92
... ... ... ... ...
618 2018-03-05 Saturday 10066059228 Open xx 2 56.0 49.28
619 2018-03-22 Tuesday 10035514928 Open xx 1 28.0 25.00
620 2018-04-15 Friday 1006668328 Open xx 2 56.0 50.00
621 2018-04-24 Sunday 10073294128 Gott xx Ling 1 5.6 5.60
622 2018-04-24 Sunday 10073294128 Gott xxling 10 56.0 56.0
623 rows × 6 columns
````

##### Create `DataFrame` object by reading data from database through SQL

The `read_sql` function of the `pandas` module can create a `DataFrame` object by reading data from the database through SQL statements. The second parameter of the function represents the database to be connected to. For MySQL database, we can create a database connection through `pymysql` or `mysqlclient`, and get a `Connection` object, which is the second parameter required by the `read_sql` function, the code is as follows.

Code:

````Python
import pymysql

# Create a connection object to the MySQL database
conn = pymysql.connect(
    host='47.104.31.138', port=3306,
    user='guest', password='Guest.618',
    database='hrs', charset='utf8mb4'
)
# Create DataFrame by reading data from database through SQL
df5 = pd.read_sql('select * from tb_emp', conn, index_col='eno')
df5
````

> **Tips**: To execute the above code, you need to install the `pymysql` library first. If it is not installed, you can execute `!pip install pymysql` in the notebook cell first, and then run the above code. The above code connects to my MySQL database deployed on Alibaba Cloud, public IP address: `47.104.31.138`, username: `guest`, password: `Guest.618`, database: `hrs`, table name : `tb_emp`, character set: `utf8mb4`, you can use this database, but do not make malicious access.

output:


````
        ename job mgr sal comm dno
eno
1359 Hu Yidao Salesperson 3344.0 1800 200.0 30
2056 Qiao Feng Analyst 7800.0 5000 1500.0 20
3088 Li Mochou Designer 2056.0 3500 800.0 20
3211 Zhang Wuji Programmer 2056.0 3200 NaN 20
3233 Qiu Chuji Programmer 2056.0 3400 NaN 20
3244 Ouyang Feng Programmer 3088.0 3200 NaN 20
3251 Zhang Cuishan Programmer 2056.0 4000 NaN 20
3344 Huang Rong Sales Supervisor 7800.0 3000 800.0 30
3577 Yang Guo Accounting 5566.0 2200 NaN 10
3588 Zhu Jiuzhen Accounting 5566.0 2500 NaN 10
4466 Miao Renfeng Salesperson 3344.0 2500 NaN 30
5234 Guo Jing Cashier 5566.0 2000 NaN 10
5566 Song Yuanqiao Accountant 7800.0 4000 1000.0 10
7800 Zhang Sanfeng President NaN 9000 1200.0 20
````

#### Basic properties and methods

Before starting to explain the properties and methods of `DataFrame`, we first read the data of three tables from the `hrs` database mentioned earlier, and create three `DataFrame` objects, the code is as follows.

````Python
import pymysql

conn = pymysql.connect(
    host='47.104.31.138', port=3306,
    user='guest', password='Guest.618',
    database='hrs', charset='utf8mb4'
)
dept_df = pd.read_sql('select * from tb_dept', conn, index_col='dno')
emp_df = pd.read_sql('select * from tb_emp', conn, index_col='eno')
emp2_df = pd.read_sql('select * from tb_emp2', conn, index_col='eno')
````

The resulting three `DataFrame` objects are shown below.

A department table (`dept_df`), where `dno` is the number of the department and `dname` and `dloc` are the name and location of the department, respectively.

````
    dname dloc
dno
10 Accounting Department Beijing
20 R&D Department Chengdu
30 Sales Department Chongqing
40 Operation and Maintenance Department Tianjin
````


Employee table (`emp_df`), where `eno` is the employee number, `ename`, `job`, `mgr`, `sal`, `comm` and `dno` represent the employee's name, position, supervisor number, Monthly salary, allowance and department number.

````
        ename job mgr sal comm dno
eno
1359 Hu Yidao Salesperson 3344.0 1800 200.0 30
2056 Qiao Feng Analyst 7800.0 5000 1500.0 20
3088 Li Mochou Designer 2056.0 3500 800.0 20
3211 Zhang Wuji Programmer 2056.0 3200 NaN 20
3233 Qiu Chuji Programmer 2056.0 3400 NaN 20
3244 Ouyang Feng Programmer 3088.0 3200 NaN 20
3251 Zhang Cuishan Programmer 2056.0 4000 NaN 20
3344 Huang Rong Sales Supervisor 7800.0 3000 800.0 30
3577 Yang Guo Accounting 5566.0 2200 NaN 10
3588 Zhu Jiuzhen Accounting 5566.0 2500 NaN 10
4466 Miao Renfeng Salesperson 3344.0 2500 NaN 30
5234 Guo Jing Cashier 5566.0 2000 NaN 10
5566 Song Yuanqiao Accountant 7800.0 4000 1000.0 10
7800 Zhang Sanfeng President NaN 9000 1200.0 20
````

> **Description**: The data types of the two columns `mgr` and `comm` in the database are `int`, but because there are missing values ​​(null values), after reading the `DataFrame`, the data types of the columns Becomes `float`, because we usually use `NaN` of type `float` to represent null values.

The employee table (`emp2_df`) has the same structure as the employee table above, but saves different employee data.

````
        ename job mgr sal comm dno
eno
9800 Luo Hao Architect 7800 30000 5000 20
9900 Wang Xiaodao Programmer 9800 10000 1200 20
9700 Wang sledgehammer Programmer 9800 8000 600 20
````

The properties of the `DataFrame` object are shown in the following table.

| attribute name | description |
| -------------- | ---------------------------------- - |
| `at` / `iat` | Get a single value in a `DataFrame` by label. |
| `columns` | `DataFrame` object column index |
| `dtypes` | The data type of each column of the `DataFrame` object |
| `empty` | Whether the `DataFrame` object is empty |
| `loc` / `iloc` | Get a set of values ​​in a `DataFrame` by label. |
| `ndim` | The dimensions of the `DataFrame` object |
| `shape` | The shape of the `DataFrame` object (number of rows and columns) |
| `size` | The number of elements in the `DataFrame` object |
| `values` | The two-dimensional array corresponding to the data of the `DataFrame` object |

Regarding the method of `DataFrame`, the first thing you need to know is the `info()` method, which can help us understand the relevant information of `DataFrame`, as shown below.

Code:

````Python
emp_df.info()
````


output:

````
<class 'pandas.core.frame.DataFrame'>
Int64Index: 14 entries, 1359 to 7800
Data columns (total 6 columns):
 # Column Non-Null Count Dtype
--- ------ -------------- -----
 0 ename 14 non-null object
 1 job 14 non-null objects
 2 mgr 13 non-null float64
 3 sal 14 non-null int64
 4 comm 6 non-null float64
 5 dno 14 non-null int64
dtypes: float64(2), int64(2), object(2)
memory usage: 1.3+ KB
````

If you need to view the data at the head or tail of the `DataFrame`, you can use the `head()` or `tail()` method. The default parameter of these two methods is `5`, which means to get the first 5 rows of the `DataFrame` or the last 5 rows of data as shown below.

````Python
emp_df.head()
````

output:

````
        ename job mgr sal comm dno
eno
1359 Hu Yidao Salesperson 3344 1800 200 30
2056 Qiao Feng Analyst 7800 5000 1500 20
3088 Li Mochou Designer 2056 3500 800 20
3211 Zhang Wuji Programmer 2056 3200 NaN 20
3233 Qiu Chuji Programmer 2056 3400 NaN 20
````

#### retrieve data

##### Indexing and Slicing

If you want to get a column of `DataFrame`, such as the `ename` column of `emp_df` above, you can use the following two methods.

````Python
emp_df.ename
````

or

````Python
emp_df['ename']
````

Executing the above code can find that what we get is a `Series` object. In fact, a `DataFrame` object is the result of combining multiple `Series` objects together.

If you want to get a certain row of `DataFrame`, you can use the integer index or the index we set, for example, to get the employee data whose employee number is `2056`, the code is as follows.

````Python
emp_df.iloc[1]
````

or

````Python
emp_df.loc[2056]
````


By executing the above code, we find that fetching a row or a column of a `DataFrame` by itself is a `Series` object. Of course, we can also get data of multiple rows or multiple columns through fancy indexing, and the result of fancy indexing is still a `DataFrame` object.

Get multiple columns:

````Python
emp_df[['ename', 'job']]
````

Get multiple rows:

````Python
emp_df.loc[[2056, 7800, 3344]]
````

If you want to get or modify the data of a cell of the `DataFrame` object, you need to specify the index of the row and column at the same time. For example, to get the position information of the employee whose employee number is `2056`, the code is as follows.

````Python
emp_df['job'][2056]
````

or

````Python
emp_df.loc[2056]['job']
````

or

````Python
emp_df.loc[2056, 'job']
````

We recommend that you use the third method, because it does only one indexing operation. If you want to modify the employee's job title to "Architect", you can use the code below.

````Python
emp_df.loc[2056, 'job'] = 'Architect'
````

Of course, we can also obtain multiple rows and multiple columns through slicing operations. I believe you must have already thought of this.

````Python
emp_df.loc[2056:3344]
````

output:

````
        ename job mgr sal comm dno
eno
2056 Qiao Feng Analyst 7800.0 5000 1500.0 20
3088 Li Mochou Designer 2056.0 3500 800.0 20
3211 Zhang Wuji Programmer 2056.0 3200 NaN 20
3233 Qiu Chuji Programmer 2056.0 3400 NaN 20
3244 Ouyang Feng Programmer 3088.0 3200 NaN 20
3251 Zhang Cuishan Programmer 2056.0 4000 NaN 20
3344 Huang Rong Sales Supervisor 7800.0 3000 800.0 30
````

##### Data filtering

We mentioned fancy indexes above, and I believe you have already thought of Boolean indexes. Like `ndarray` and `Series`, we can filter the `DataFrame` object by boolean index. For example, we want to filter out the employees whose monthly salary is more than `3500` from `emp_df`, the code is as follows.

````Python
emp_df[emp_df.sal > 3500]
````

output:

````
        ename job mgr sal comm dno
eno
2056 Qiao Feng Analyst 7800.0 5000 1500.0 20
3251 Zhang Cuishan Programmer 2056.0 4000 NaN 20
5566 Song Yuanqiao Accountant 7800.0 4000 1000.0 10
7800 Zhang Sanfeng President NaN 9000 1200.0 20
````


Of course, we can also combine multiple conditions to filter data, for example, from `emp_df` to filter out employees whose monthly salary exceeds `3500` and the department number is `20`, the code is as follows.

````Python
emp_df[(emp_df.sal > 3500) & (emp_df.dno == 20)]
````

output:

````
        ename job mgr sal comm dno
eno
2056 Qiao Feng Analyst 7800.0 5000 1500.0 20
3251 Zhang Cuishan Programmer 2056.0 4000 NaN 20
7800 Zhang Sanfeng President NaN 9000 1200.0 20
````

In addition to using Boolean indexes, the `query` method of the `DataFrame` object can also implement data filtering. The parameter of the `query` method is a string, which represents the expression used to filter data, and is more in line with the usage habits of Python programmers . Next, we use the `query` method to re-implement the above effect, the code is as follows.

````Python
emp_df.query('sal > 3500 and dno == 20')
````

#### reshape data

Sometimes, the original data we need for data analysis may not come from a single place. As in the above example, we read three tables from a relational database and obtained three `DataFrame` objects, but the actual Jobs may require us to bring their data together. For example: `emp_df` and `emp2_df` are actually employee data, and the data structure is exactly the same, we can use the `concat` function provided by `pandas` to realize the data splicing of two or more `DataFrame`, the code is as follows Show.

````Python
all_emp_df = pd.concat([emp_df, emp2_df])
````

output:

````
        ename job mgr sal comm dno
eno
1359 Hu Yidao Salesperson 3344.0 1800 200.0 30
2056 Qiao Feng Analyst 7800.0 5000 1500.0 20
3088 Li Mochou Designer 2056.0 3500 800.0 20
3211 Zhang Wuji Programmer 2056.0 3200 NaN 20
3233 Qiu Chuji Programmer 2056.0 3400 NaN 20
3244 Ouyang Feng Programmer 3088.0 3200 NaN 20
3251 Zhang Cuishan Programmer 2056.0 4000 NaN 20
3344 Huang Rong Sales Supervisor 7800.0 3000 800.0 30
3577 Yang Guo Accounting 5566.0 2200 NaN 10
3588 Zhu Jiuzhen Accounting 5566.0 2500 NaN 10
4466 Miao Renfeng Salesperson 3344.0 2500 NaN 30
5234 Guo Jing Cashier 5566.0 2000 NaN 10
5566 Song Yuanqiao Accountant 7800.0 4000 1000.0 10
7800 Zhang Sanfeng President NaN 9000 1200.0 20
9800 Luo Hao Architect 7800.0 30000 5000.0 20
9900 Wang Xiaodao Programmer 9800.0 10000 1200.0 20
9700 Wang sledgehammer Programmer 9800.0 8000 600.0 20
````

The above code concatenates two `DataFrame` representing employee data, and then we use the `merge` function to merge the data of the employee table and the department table into one table, the code is as follows.

First use the `reset_index` method to reset the index of `all_emp_df`, so that `eno` is no longer an index but an ordinary column. The `inplace` parameter of the `reset_index` method is set to `True`, indicating that the operation of resetting the index is directly Execute on `all_emp_df` instead of returning a new modified object.

````Python
all_emp_df.reset_index(inplace=True)
````

The data is merged through the `merge` function, of course, you can also call the `merge` method of the `DataFrame` object to achieve the same effect.

````Python
pd.merge(dept_df, all_emp_df, how='inner', on='dno')
````

output:

````
    dno dname dloc eno ename job mgr sal comm
0 10 Accounting Department Beijing 3577 Yang Guo Accounting 5566.0 2200 NaN
1 10 Accounting Department Beijing 3588 Zhu Jiuzhen Accounting 5566.0 2500 NaN
2 10 Accounting Department Beijing 5234 Guo Jing Cashier 5566.0 2000 NaN
3 10 Accounting Department Beijing 5566 Song Yuanqiao Accountant 7800.0 4000 1000.0
4 20 R&D Department Chengdu 2056 Qiao Feng Architect 7800.0 5000 1500.0
5 20 R&D Department Chengdu 3088 Li Mochou Designer 2056.0 3500 800.0
6 20 R&D Department Chengdu 3211 Zhang Wuji Programmer 2056.0 3200 NaN
7 20 R&D Department Chengdu 3233 Qiu Chuji Programmer 2056.0 3400 NaN
8 20 R&D Department Chengdu 3244 Ouyang Feng Programmer 3088.0 3200 NaN
9 20 R&D Department Chengdu 3251 Zhang Cuishan Programmer 2056.0 4000 NaN
10 20 R&D Department Chengdu 7800 Zhang Sanfeng President NaN 9000 1200.0
11 20 R&D Department Chengdu 9800 Luo Hao Architect 7800.0 30000 5000.0
12 20 R&D Department Chengdu 9900 Wang Xiaodao Programmer 9800.0 10000 1200.0
13 20 R&D Department Chengdu 9700 Wang Dazhui Programmer 9800.0 8000 600.0
14 30 Sales Department Chongqing 1359 Hu Yidao Salesperson 3344.0 1800 200.0
15 30 Sales Department Chongqing 3344 Huang Rong Sales Supervisor 7800.0 3000 800.0
16 30 Sales Department Chongqing 4466 Miao Renfeng Salesperson 3344.0 2500 NaN
````


`One parameter of the merge` function represents the merged left table, and the second parameter represents the merged right table. Students with SQL programming experience are very kind to these two words. As you can guess, the merging of `DataFrame` objects is very similar to the table join in the database, so the `how` in the above code represents the way to merge two tables, there are `left`, `right`, `inner` , `outer` four options; and `on` represents the column based on which table is merged, which is equivalent to the join table condition in SQL table join. If the column names corresponding to the left and right tables are different, you can use `left_on` and the `right_on` parameter instead of the `on` parameter to be specified separately.

If you slightly modify the above code and change the `how` parameter to `left`, you can think about the result of the code execution.

````Python
pd.merge(dept_df, all_emp_df, how='left', on='dno')
````

The running result has one more line than the previous output. This is because `left` represents a left outer join, which means that the data in the left table `dept_df` will be completely checked out, but in `all_emp_df` There is no employee numbered in the department `40`, so the corresponding positions are filled with empty values.

````
17 40 Operation and Maintenance Department Tianjin NaN NaN NaN NaN NaN NaN
````