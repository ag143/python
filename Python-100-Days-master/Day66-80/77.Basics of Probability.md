## Probabilistic basis

### Central tendency of data

We often use the following indicators to describe the central tendency of a set of data:

1. Average - The average represents the overall level of a data set. The indicators we often mention such as unit price, average visit time, and average delivery time are all averages. The disadvantage of the mean is that it is easily affected by extreme values. Although the weighted average can be used to eliminate the influence of extreme values, the weight of the data may not be known in advance; for positive numbers, the geometric mean can be used instead of the arithmetic mean.
    - Arithmetic mean: $$\bar{x}=\frac{\sum_{i=1}^{n}x_{i}}{n}=\frac{x_{1}+x_{2}+\ cdots +x_{n}}{n}$$, for example, to calculate the average daily DAU in the last 30 days, the average daily new visitors, etc., the arithmetic average can be used.
    - Geometric mean: $$\left(\prod_{i=1}^{n}x_{i}\right)^{\frac{1}{n}}={\sqrt[{n}]{x_ {1}x_{2} \cdots x_{n}}}$$, such as calculating the average conversion rate of different channels, the average retention rate of different customer groups, the average payment rate of different categories, etc., the geometric mean can be used.
2. Median - The middle number after sorting the data in ascending or descending order, it describes the median level of the data.
3. Mode - The most frequent data in the data set, it represents the general level of the data. The more concentrated the trends in the data, the better the representation of the mode. The mode is not affected by extreme values, but its uniqueness and existence cannot be guaranteed.

Example: There are two sets of data, A and B.

````
Group A: 5, 6, 6, 6, 6, 8, 10
Group B: 3, 5, 5, 6, 6, 9, 12
````

Mean: 6.74, Median: 6, Mode: 6 in Group A.

Group B's mean: 6.57, median: 6, mode: 5, 6.

> **Note**: In Excel, you can use the AVERAGE, MEDIAN, and MODE functions to calculate the mean, median, and mode, respectively. To find the median, you can also use the QUARTILE.EXC or QUARTILE.INC functions, and set the second parameter to 2.

Make some adjustments to the data in Group A.

````
Group A: 5, 6, 6, 6, 6, 8, 10, 200
Group B: 3, 5, 5, 6, 6, 9, 12
````

The mean of group A will increase substantially, but the median and mode will not change.

> **Thinking**: How to judge whether the above 200 is an outlier?

| | Advantages | Disadvantages |
| ------ | -------------------------------- | --------- --------------------------- |
| Mean | Makes full use of all data and is highly adaptable | Easily affected by extreme values ​​(outliers) |
| Median | Able to avoid the influence of extreme values ​​(outliers) | Insensitive |
| Mode | Can well reflect the central tendency of the data | It may not exist (the data has no obvious central tendency) |

> **Exercise 1**: In the form "Exercise 1" of the "Probability Basic Exercise.xlsx" file, there is a set of data on the payment amount of the user's order, and the mean, median and mode of the order are calculated.
>
> **Exercise 2:** In the form "Exercise 2" of the "Probability Basic Exercise.xlsx" file, there is a set of data on the sales volume of commodities. It is now planned to set a threshold, and carry out the analysis on the distributors corresponding to the commodities below the threshold. Optimization, what should be selected as the appropriate threshold?

### Discrete trend of data

If the central trend of the data shows what the most important feature of the data is; then the discrete trend of the data reflects the stability of this feature. For example, the average temperature in winter in area A is `0` degrees Celsius, and the minimum temperature is `-10` degrees Celsius; the average temperature in winter in area B is `-2` degrees Celsius, and the minimum temperature is `-4` degrees Celsius; if you are a person who is particularly afraid of cold, choose When two areas, A and B, are the cities where you work and live, what choices will you make?

1. Extreme values: the maximum and minimum values, which represent the upper and lower limits of the data set.

    > **Note**: In Excel, the functions for calculating extreme values ​​are MAX and MIN.

2. Range: Also known as "full range", it is the difference between the largest observed value and the smallest observed value in a set of data, denoted as $R$. In general, the larger the range, the greater the degree of dispersion, and the more severely the data is affected by the extreme value.

3. Interquartile distance: $IQR = Q_3 - Q_1$.

4. Variance: The value obtained by squaring the deviation of each value from the mean and dividing by the total amount of data. Simply put, it is the degree to which the data deviates from the expected value. The larger the variance, the more unstable the data and the more violent the fluctuation, so it represents that the data as a whole is relatively scattered, showing a discrete trend; while the smaller the variance, it means that the data is more stable and the fluctuation is smoother, so it represents the overall data. relatively concentrated.
    - Population variance: $$ \sigma^2 = \frac {\sum_{i=1}^{N}(X_i - \mu)^2} {N} $$.
    - Sample variance: $$ S^2 = \frac {\sum_{i=1}^{N}(X_i - \bar{X})^2} {N-1} $$.

    > **Note**: In Excel, the functions for calculating population variance and sample variance are VAR.P and VAR.S, respectively.

5. Standard deviation: The result of the square root operation of the variance, like the variance, indicates the degree of deviation of the data from the expected value.
    - Population standard deviation: $$ \sigma = \sqrt{\frac{\sum_{i=1}^{N}(X_i - \mu)^2}{N}} $$.
    - Sample standard deviation: $$ S = \sqrt{\frac{\sum_{i=1}^{N}(X_i - \bar{X})^2}{N-1}} $$.

    > **Note**: In Excel, the functions to calculate the standard deviation are STDEV.P and STDEV.S.

> **Exercise 3**: Copy the form "Exercise 1" of the "Probability Basic Exercise.xlsx" file, name the copied form "Exercise 3", and calculate the maximum, minimum, range, and variance of the order payment amount and standard deviation.

### Frequency analysis of data

Frequency analysis refers to a method of grouping data in a certain way, then counting the number of samples in each group, and then supplementing it with graphs (such as histograms) to more intuitively display the trend of data distribution.

The meaning of frequency analysis:

1. Big problems become small problems, and quickly focus on the groups that need attention.
2. Find a reasonable classification mechanism, which is conducive to long-term data analysis (dimension disassembly).

Example: There are 40 students in a class, and the test scores are as follows:

````
73, 87, 88, 65, 73, 76, 80, 95, 83, 69, 55, 67, 70, 94, 86, 81, 87, 95, 84, 92, 92, 76, 69, 97, 72, 90, 72, 85, 80, 83, 97, 95, 62, 92, 67, 73, 91, 95, 86, 77
````

Using the knowledge learned above, first interpret the data of students' test scores.

Mean: 81.275, Median: 83, Mode: 95.

Highest Score: 97, Lowest Score: 55, Range: 42, Variance: 118.15, Standard Deviation: 10.87.

However, it is difficult to make a comprehensive interpretation of a data set only by relying on the above data. We can group students according to their test scores, as shown below. You can try to complete this operation in Excel or Python.

| Fractions | Number of Students |
| -------- | -------- |
| <60 | 1 |
| [60, 65) | 1 |
| [65, 69) | 5 |
| [70, 75) | 6 |
| [75, 80) | 3 |
| [80, 85) | 6 |
| [85, 90) | 6 |
| [90, 95) | 6 |
| >=95 | 6 |

> **Exercise 4**: In the form "Exercise 4" of the "Probability Basic Exercise.xlsx" file, there is the A/B test data after the iterative launch of the homepage version of an App. Active days, please analyze the data of group A and group B and decide which group performs better.
>
> **Exercise 5**: In the form "Exercise 5" of the "Probability Basic Exercise.xlsx" file, there is A/B test data after a certain function of an App is iteratively launched. The data represents the users who participated in the test for 30 days , please analyze the data of group A and group B and determine which group performs better.

### Probability distribution of data

#### basic concept

1. Random experiment: An experiment in which a random phenomenon is observed under the same conditions. Randomized trials satisfy three characteristics:
    - Can be repeated under the same conditions.
    - More than one outcome per trial, all possible outcomes can be clearly indicated in advance.
    - The results of repeated trials appear in a random fashion (it is not known in advance which results will appear).

2. Random variables: If $X$ is assigned to the probability space $S$, each event $e$ has a real number $X(e)$, and for each real number $r$ there is a set of events $A_r$ and its Correspondingly, where $A_r=\{e: X(e) \le r\}$, then $X$ is called a random variable. From this definition, it can be seen that the essence of $X$ is a real-valued function, a real-valued function with a given event as an independent variable, because the function will generate a dependent variable when the independent variable is given, so $X$ is called random. variable.

    - Discrete random variables: data can be listed one by one.
    - Continuous random variables: data cannot be listed one by one.

    If the value of a discrete random variable is very large, it can be approximately regarded as a continuous random variable.

3. Probability Mass Function/Probability Density Function: The probability mass function is a function that describes the probability of a discrete random variable taking a specific value, usually abbreviated as **PMF**. The probability density function is a function that describes the probability of a continuous random variable at a certain value point, usually abbreviated as **PDF**. The difference between the two is that the probability density function itself is not a probability, and only after the probability density function is integrated in a certain interval is the probability.

#### Discrete distribution

1. Bernoulli distribution (*Bernoulli distribution*): Also known as **two-point distribution** or **0-1 distribution**, it is a discrete probability distribution. If the Bernoulli experiment is successful, the random variable takes the value 1. If the Bernoulli experiment fails, the random variable takes the value 0. Note that the probability of success is $p (0 \le p \le 1)$, and the probability of failure is $q=1-p$, then the probability mass function is:

    $$ {\displaystyle f_{X}(x)=p^{x}(1-p)^{1-x}=\left\{{\begin{matrix}p&{\mbox{if }}x= 1,\\q\ &{\mbox{if }}x=0.\\\end{matrix}}\right.} $$

2. Binomial distribution (*Binomial distribution*): A discrete probability distribution of the number of successes in n independent yes/no trials, where the probability of success per trial is p. In general, if the random variable $X$ obeys the binomial distribution with parameters $n$ and $p$, it is recorded as $X\sim B(n,p)$. The probability of getting exactly $k$ successes in $n$ trials is given by the probability mass function, $\displaystyle f(k,n,p)=\Pr(X=k)={n \choose k}p^ {k}(1-p)^{n-k}$, for $k= 0, 1, 2, ..., n$, where ${n \choose k}={\frac {n!}{k! (n-k)!}}$.

3. Poisson distribution (*Poisson distribution*): A probability distribution suitable for describing the number of random events occurring per unit time. For example, the number of service requests received by a service facility within a certain period of time, the number of waiting guests at the bus station, the number of machine failures, the number of natural disasters, the number of DNA sequence mutations, the number of radioactive nuclei decay, and so on. The probability mass function of the Poisson distribution is: $P(X=k)=\frac{e^{-\lambda}\lambda^k}{k!}$, and the parameter $\lambda$ of the Poisson distribution is the unit time The average incidence of random events within (or per unit area).

    > **Note**: Poisson distribution is an approximation provided by mathematicians for the binomial distribution in order to reduce the computational complexity in the age of no computer.

#### Distribution function and density function

For continuous random variables, it is impossible to list the probability of occurrence of each value, so the concept of distribution function must be introduced.
$$
F(x) = P\{X \le x\}
$$
If you think of $ X $ as a random coordinate on the number line, the above distribution function represents the probability that $ x $ falls in the interval $ (-\infty, x) $. The distribution function has the following properties:

1. $ F(x) $ is a monotonically non-decreasing function;
2. $ 0 \le F(x) \le 1$, and $ F(-\infty) = \lim_{x \to -\infty} F(x) = 0 $, $F(\infty) = \ lim_{x \to \infty} F(x) = 1$;
3. $F(x)$ is right continuous.

The probability density function is the result of derivation of the distribution function, which is simply:
$$
F(x) = \int_{- \infty}^{x} f(t)dt
$$

#### Continuous distribution

1. Uniform distribution (*Uniform distribution*): If a continuous random variable $X$ has a probability density function $f(x)=\begin{cases}{\frac{1}{b-a}} \quad &{a \ leq x \leq b} \\ {0} \quad &{\mbox{other}}\end{cases}$, then $X$ is said to obey a uniform distribution on $[a,b]$, denoted by $X \sim U[a,b]$.

2. Exponential distribution (*Exponential distribution*): If a continuous random variable $X$ has a probability density function $f(x)=\begin{cases} \lambda e^{- \lambda x} \quad &{x \ ge 0} \\ {0} \quad &{x \lt 0} \end{cases}$, then $X$ is said to obey the exponential distribution with parameter $\lambda$, denoted as $X \sim Exp(\lambda )$. Exponential distributions can be used to represent the time interval between independent random events, such as the time interval between passengers entering the airport, the time interval between calling a customer service center, and the time interval between new issues on Zhihu, etc. An important feature of the exponential distribution is memorylessness (no aftereffect), which means that if a random variable is exponentially distributed, its conditional probability follows: $P(T \gt s+t\ |\ T \gt t) =P(T \gt s), \forall s,t \ge 0$.

3. Normal distribution (*Normal distribution*): also known as **Gaussian distribution** (*Gaussian distribution*), is a very common continuous probability distribution, often used in natural and social sciences to represent an unknown random variable. If the random variable $X$ obeys a normal distribution whose location parameter is $\mu$ and scale parameter is $\sigma$, denoted as $X \sim N(\mu,\sigma^2)$, its probability density function is: $\displaystyle f(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {\left(x-\mu \right)^{ 2}}{2\sigma ^{2}}}}$.

    <img src="https://gitee.com/jackfrued/mypic/raw/master/20210716155507.png" width="80%">

    "3$\sigma$ rule":

    <img src="https://gitee.com/jackfrued/mypic/raw/master/20210716155542.png" width="75%">

    The normal distribution has a very important property, **The distribution of the mean of a large number of statistically independent random variables tends to be normally distributed**, which is the **Central Limit Theorem**. The significance of the Central Limit Theorem is that we can use the normal distribution as an approximation to other probability distributions.

    An example: Suppose the average score and standard deviation on an intelligence test of freshmen entering a school are 100 and 12, respectively. So what is the probability that 50 students are randomly selected to have an average intelligence test score greater than 105? What is the probability of being less than 90?

    There is no assumption of normal distribution in this example. Fortunately, the central limit theorem provides a feasible solution, that is, when the number of random samples exceeds 30, the sample mean is approximately a normal variable, and the standard normal variable $ Z = \frac {\bar {X} - \mu} {\sigma / \sqrt{n}} $.

    The probability that the mean score is greater than 105 is: $ P(Z \gt \frac{105 - 100}{12 / \sqrt{50}}) = P(Z \gt 5/1.7) = P(Z \gt 2.94) = 0.0016$.

    The probability that the mean score is less than 90 is: $ P(Z \lt \frac{90-100}{12/\sqrt{50}}) = P(Z < -5.88) = 0.0000 $.

    > **Note**: The probability value of the above standard normal distribution can be obtained by looking up the table.

4. Gamma distribution (*Gamma distribution*): Assuming $X_1, X_2, ... X_n$ are the waiting times for consecutive events, and the $n$ waiting times are independent, then the $n$ waiting times The sum of time $Y$ ($Y=X_1+X_2+...+X_n$) obeys the gamma distribution, ie $Y \sim \Gamma(\alpha,\beta)$, where $\alpha=n, \beta =\lambda$, where $\lambda$ is the average frequency of consecutive events.

5. Chi-square distribution (*Chi-square distribution*): If $k$ random variables $Z_1, Z_2,..., Z_k$ are independent of each other and conform to the standard normal distribution (mathematical expectation is 0, variance is 1 ), then the sum of squares of the random variable $Z$$X=\sum_{i=1}^{k}Z_i^2$ is said to obey the chi-square distribution with degrees of freedom $k$, denoted as $ X \sim \chi^2(k)$.

### Other content

#### Conditional Probability and Bayes' Theorem

**Conditional probability** refers to the probability that event A occurs under the condition that event B occurs, usually recorded as $P(A|B)$. Let A and B be two events in the sample space $\Omega$, where $P(B) \gt 0$. Then under the condition that event B occurs, the conditional probability of event A occurring is: $P(A|B)=\frac{P(A \cap B)}{P(B)}$, where $P(A \ cap B)$ is the joint probability, that is, the probability that two events A and B occur together.

The probability of event A occurring under the condition that event B has occurred is not the same as the probability of event B occurring under the condition that event A has occurred. However, there is a definite relationship between the two, and Bayes' theorem is a statement of this relationship, namely: $P(A|B)=\frac{P(A)P(B|A )}{P(B)}$, where:

- $P(A|B)$ is the conditional probability of A after the known occurrence of B, also known as the posterior probability of A.
- $P(A)$ is the prior probability (also known as marginal probability) of A, which is the probability that A occurs without considering B.
- $P(B|A)$ is the conditional probability of B after it is known that A occurs, which is called the likelihood of B.
- $P(B)$ is the prior probability of B.

According to the above description, Bayes' theorem can be expressed as: `Posterior probability = (Likelihood * Prior probability) / Standardized constant`​, simply put, the product of the posterior probability and the prior probability and the similarity proportional.

#### Theorem of Large Numbers

The larger the sample size, the higher the probability that its arithmetic mean will be close to the expected value.

1. Weak law of large numbers (Xinqin's theorem): The sample mean converges to the expected value according to probability, that is, for any positive number $\epsilon$, there are: $\lim_{n \to \infty}P(|\bar{X_n} -\mu|>\epsilon)=0$.
2. The strong law of numbers: The sample mean converges to the expected value with probability 1, namely: $P(\lim_{n \to \infty}\bar{X_n}=\mu)=1$.

#### hypothetical test

Hypothesis testing is a method of verifying the overall situation by extracting sample data and verifying the overall situation through the **small-probability contradictory method**. The core idea of ​​hypothesis testing is the small-probability rebuttal method (first assume that the proposition to be overturned is true, and then try to find out the contradiction and find the unreasonable place to prove that the proposition is false), that is, in the **null hypothesis** (null Under the premise of the hypothesis), estimate the possibility of an event occurring. If the event is a small probability event, it would have been impossible in a study, but it has happened now. At this time, the null hypothesis can be overturned and the ** Alternative hypothesis** (alternative hypothesis). If the event is not a low probability event, we can find no reason to reject the previous hypothesis, which can actually be extended to accept the null hypothesis made.

There are two kinds of errors in hypothesis testing, one is called "rejection of the truth", and the other is called "false". If the null hypothesis is correct, but you reject the null hypothesis, this error is called "rejection", and the probability of this error is also called the significance level $\alpha $, or tolerance; if the null hypothesis is Wrong, but you admit the null hypothesis, this kind of error is called "falsification", and the probability of this error is recorded as $\beta$.

### Summarize

Descriptive statistics are usually used to study appearances and describe phenomena in terms of data (using overall data to describe the characteristics of the whole); inferential statistics are usually used to infer the essence (using sample data characteristics to infer overall data characteristics), and also It is the probability that what you see on the surface is consistent with your guess about the essence hidden behind the appearance.