## Pandas application-4

### Application of DataFrame

#### data analysis

After the previous study, we have the data ready and become what we want, the next step is the most important data analysis stage. When we get a lot of data, how to quickly interpret valuable information from the data is the problem to be solved by data analysis. First, we can obtain descriptive statistics of the data, through which we can understand the central and discrete trends of the data.

For example, we have the student grade sheet shown below.

````Python
import numpy as np
import pandas as pd

scores = np.random.randint(50, 101, (5, 3))
names = ('Guan Yu', 'Zhang Fei', 'Zhao Yun', 'Ma Chao', 'Huang Zhong')
courses = ('Chinese', 'Math', 'English')
df = pd.DataFrame(data=scores, columns=courses, index=names)
df
````

output:

````
     Chinese Mathematics English
Guan Yu 96 72 73
Zhang Fei 72 70 97
Zhao Yun 74 51 79
Ma Chao 100 54 54
Huang Zhong 89 100 88
````

We can obtain the average, highest, lowest, and standard scores of each student or each course through the methods `mean`, `max`, `min`, `std`, `var` and other methods of the `DataFrame` object. Difference, variance and other information, you can also directly obtain descriptive statistics through the `describe` method. The code is as follows.

Calculate the average of grades for each course.

````Python
df.mean()
````

output:

````
Language 86.2
Mathematics 69.4
English 78.2
dtype: float64
````

Calculate the average of each student's grades.

````Python
df.mean(axis=1)
````

output:

````
Guan Yu 80.333333
Zhang Fei 79.666667
Zhao Yun 68.000000
Ma Chao 69.333333
Huang Zhong 92.333333
dtype: float64
````

Calculate the variance of grades for each course.

````Python
df.var()
````

output:

````
Language 161.2
Mathematics 379.8
English 265.7
dtype: float64
````

> **Note**: It can be seen from the variance that math scores fluctuate the most and are the most unstable.

Get descriptive statistics for each course.

````Python
df.describe()
````

output:

````
        Chinese Mathematics English
count 5.000000 5.000000 5.000000
mean 86.200000 69.400000 78.200000
std 12.696456 19.488458 16.300307
min 72.000000 51.000000 54.000000
25% 74.000000 54.000000 73.000000
50% 89.000000 70.000000 79.000000
75% 96.000000 72.000000 88.000000
max 100.000000 100.000000 97.000000
````

##### Sorting and Top-N

If you need to sort the data, you can use the `sort_values` method of the `DataFrame` object. The `by` parameter of this method can specify which column or columns to sort by, and the `ascending` parameter can specify ascending or descending order. For example, the code below shows how to sort the student table in descending order by language scores.

````Python
df.sort_values(by='language', ascending=False)
````

output:

````
      Chinese Mathematics English
Ma Chao 100 54 54
Guan Yu 96 72 73
Huang Zhong 89 100 88
Zhao Yun 74 51 79
Zhang Fei 72 70 97
````

If the `DataFrame` has a large amount of data, sorting will be a very time-consuming operation. Sometimes we only need to get the top N or bottom N data. At this time, there is no need to sort the entire data, but directly use the heap structure to find the Top-N data. The `nlargest` and `nsmallest` methods of `DataFrame` provide support for the Top-N operation, the code is shown below.

Find out the information of the top 3 students in Chinese.

````Python
df.nlargest(3, 'language')
````

output:

````
      Chinese Mathematics English
Ma Chao 100 54 54
Guan Yu 96 72 73
Huang Zhong 89 100 88
````

Find out the information for the 3 students with the lowest math scores.

````Python
df.nsmallest(3, 'math')
````

output:

````
      Chinese Mathematics English
Zhao Yun 74 51 79
Ma Chao 100 54 54
Zhang Fei 72 70 97
````

##### Grouping aggregation operations

Let's first read a set of sales data from an Excel file, and then show you how to perform group aggregation operations.

````Python
df = pd.read_excel('2020 sales data.xlsx')
df.head()
````

> **Note**: If you need the Excel file in the above example, you can get it through the following Alibaba Cloud disk address, which is in the "Dataset" directory under "My Share". Address: https://www.aliyundrive.com/s/oPi7DRAVKRm.

output:

````
    Sales Date Sales Area Sales Channel Sales Order Brand Price Sales Quantity
0 2020-01-01 Shanghai Pinduoduo 182894-455 Eight Horses 99 83
1 2020-01-01 Shanghai Douyin 205635-402 Eight Horses 219 29
2 2020-01-01 Shanghai Tmall 205654-021 Eight horses 169 85
3 2020-01-01 Shanghai Tmall 205654-519 Eight horses 169 14
4 2020-01-01 Shanghai Tmall 377781-010 Pipi Shrimp 249 61
````

If we want to count the total sales of each sales area, we can first calculate the sales by "selling price" and "sales quantity", add a column to the `DataFrame`, the code is as follows.

````Python
df['Sales'] = df['Sales'] * df['Quantity']
df.head()
````

output:

````
    Sales Date Sales Area Sales Channel Sales Order Brand Price Sales Quantity Sales
0 2020-01-01 Shanghai Pinduoduo 182894-455 Eight Horses 99 83 8217
1 2020-01-01 Shanghai Douyin 205635-402 Eight Horses 219 29 6351
2 2020-01-01 Shanghai Tmall 205654-021 Eight Horses 169 85 14365
3 2020-01-01 Shanghai Tmall 205654-519 Eight Horses 169 14 2366
4 2020-01-01 Shanghai Tmall 377781-010 Pipi Shrimp 249 61 15189
````

The data is then grouped according to the "Sales Area" column, here we use the `groupby` method of the `DataFrame` object. After grouping, we take the column "Sales" for sum processing within the grouping, and the code and results are shown below.

````Python
df.groupby('Sales Area').Sales.sum()
````

output:

````
Sales area
Shanghai 11610489
Beijing 12477717
Nanjing 1767301
Anhui 895463
Guangdong 1617949
Jiangsu 537079
Zhejiang 687862
Fujian 10178227
Name: Sales, dtype: int64
````

If we want to count the total sales of each month, we can use the "sale date" as the parameter of the groupby` method. Of course, we need to process the "sale date" into a month first. The code and result are as follows.

````Python
df.groupby(df['sale date'].dt.month).Sales.sum()
````

output:

````
sale date
1 5409855
2 4608455
3 4164972
4 3996770
5 3239005
6 2817936
7 3501304
8 2948189
9 2632960
10 2375385
11 2385283
12 1691973
Name: Sales, dtype: int64
````

Next, we will upgrade the difficulty and count the total monthly sales of each sales area. How should we deal with this? In fact, the first parameter of the `groupby` method can be a list, and the list can specify multiple basis for grouping. You can see the following code and output results.

````Python
df.groupby(['Sales Area', df['Sales Date'].dt.month]).Sales.sum()
````

output:

````
Sales area Sales date
Shanghai 1 1679125
          2 1689527
          3 1061193
          4 1082187
          5 841199
          6 785404
          7 863906
          8 734937
          9 1107693
         10 412108
         11 825169
         12 528041
Beijing 1 1878234
         2 1807787
         3 1360666
         4 1205989
         5 807300
         6 1216432
         7 1219083
         8 645727
         9 390077
        10 671608
        11 678668
        12 596146
Nanjing 7 841032
        10 710962
        12 215307
Anhui 4 341308
         5 554155
Guangdong 3 388180
         8 469390
         9 365191
        11 395188
Jiangsu 4 537079
Zhejiang 3 248354
         8 439508
Fujian 1 1852496
         2 1111141
         3 1106579
         4 830207
         5 1036351
         6 816100
         7 577283
         8 658627
         9 769999
        10 580707
        11 486258
        12 352479
Name: Sales, dtype: int64
````

If we want to count the total sales in each region and the highest and lowest single amount in each region, we can use the `agg` method on the `DataFrame` or `Series` object and specify multiple aggregation functions, the code and results are as follows shown.

````Python
df.groupby('Sales Area').Sales.agg(['sum', 'max', 'min'])
````

output:

````
          sum max min
Sales area
Shanghai 11610489 116303 948
Beijing 12477717 133411 690
Nanjing 1767301 87527 1089
Anhui 895463 68502 1683
Guangdong 1617949 120807 990
Jiangsu 537079 114312 3383
Zhejiang 687862 90909 3927
Fujian 10178227 87527 897
````

If you want to customize the name of the aggregated column, you can use the method shown below.

````Python
df.groupby('Sales Area').Sales.agg(Total sales='sum', Single maximum='max', Single minimum='min')
````

output:

````
          Total sales Single highest single lowest single
Sales area
Shanghai 11610489 116303 948
Beijing 12477717 133411 690
Nanjing 1767301 87527 1089
Anhui 895463 68502 1683
Guangdong 1617949 120807 990
Jiangsu 537079 114312 3383
Zhejiang 687862 90909 3927
Fujian 10178227 87527 897
````

If you need to use different aggregation functions on multiple columns, such as "statistics for the average sales per sales area and the minimum and maximum sales quantity", we can do it in the following way.

````Python
df.groupby('Sales area')[['Sales', 'Sales quantity']].agg({
    'Sales': 'mean', 'Number of sales': ['max', 'min']
})
````

output:

````
         sales sales
         mean max min
Sales area
Shanghai 20622.538188 100 10
Beijing 20125.350000 100 10
Nanjing 22370.898734 100 11
Anhui 26337.147059 98 16
Guangdong 32358.980000 98 10
Jiangsu 29837.722222 98 15
Zhejiang 27514.480000 95 20
Fujian 18306.163669 100 10
````

##### Pivot Tables and Crosstabs

In the above example, "to count the total sales of each sales area per month" will produce a result that looks very long. In practice, we usually call those tables with many rows and few columns as "narrow tables", if We don't want to get such a "narrow table", we can use the `pivot_table` method of `DataFrame` or the `pivot_table` function to generate a pivot table. The essence of pivot table is to perform grouping and aggregation operations on data. **According to column A to count column B**, if you have experience using Excel, I believe that the concept of pivot table will not be unfamiliar. For example, if we want to "count the total sales of each sales area", then "sales area" is our column A, and "sales" is our B column, corresponding to `index` and ` respectively in the `pivot_table` function The values` parameter, both of which can be a single column or multiple columns.

````Python
pd.pivot_table(df, index='Sales Area', values='Sales', aggfunc='sum')
````

output:

<img src="https://gitee.com/jackfrued/mypic/raw/master/20211106180912.png" style="zoom:50%">

> **Note**: The above result operation is somewhat different from the result obtained by the `groupby` method. After the `groupby` operation, if a single column is aggregated, the result is a `Series` object, while The result of the above is a `DataFrame` object.

If you want to count the total sales of each sales area each month, you can also use the `pivot_table` function, the code is as follows.

````Python
pd.pivot_table(df, index=['Sales Area', df['Sales Date'].dt.month], values='Sales', aggfunc='sum')
````

The result of the above operation is a `DataFrame`, but it is also a long "narrow table". If you want to make a "wide table" with fewer rows and more columns, you can put the columns in the `index` parameter into ` In the columns` parameter, the code is as follows.

````Python
pd.pivot_table(
    df, index='Sales Area', columns=df['Sales Date'].dt.month,
    values='Sales', aggfunc='sum', fill_value=0
)
````

> **Note**: `fill_value=0` of the `pivot_table` function will handle null values ​​as `0`.

output:

<img src="https://gitee.com/jackfrued/mypic/raw/master/20211106104551.png" style="zoom:50%">

When using the `pivot_table` function, you can also add the `margins` and `margins_name` parameters to summarize the results of the grouping aggregation. The specific operations and effects are as follows.

````Python
df['month'] = df['sale date'].dt.month
pd.pivot_table(
    df, index='Sales Area', columns='Month',
    values='Sales', aggfunc='sum', fill_value=0,
    margins=True, margins_name='Total'
)
````

output:

![image-20211106181707655](https://gitee.com/jackfrued/mypic/raw/master/20211106181707.png)

A crosstab is a special pivot table that does not need to construct a `DataFrame` object first, but directly specifies two or more factors through an array or a `Series` object to perform operations to obtain statistical results. For example, we want to count the total sales of each sales area, which can also be done as shown below. We first prepare three sets of data.

````Python
sales_area, sales_month, sales_amount = df['sales area'], df['month'], df['sales']
````

Use the `crosstab` function to generate a crosstab.

````Python
pd.crosstab(
    index=sales_area, columns=sales_month, values=sales_amount, aggfunc='sum'
).fillna(0).applymap(int)
````

> **Note**: The above code uses the `fillna` method of the `DataFrame` object to handle null values ​​as 0, and then uses the `applymap` method to handle the data type as an integer.

#### data visualization

A picture is worth a thousand words. The results of our pivoting of data are ultimately presented in the form of charts, because charts are extremely expressive and allow us to quickly interpret the hidden value in the data. Like `Series`, the `DataFrame` object provides the `plot` method to support drawing, and the bottom layer is still through the `matplotlib` library to achieve chart rendering. Regarding the content of `matplotlib`, we will discuss it in detail in the next chapter. Here we only briefly explain the usage of the `plot` method.

For example, if we want to compare "total sales per sales area" through a bar chart, we can use the `plot` method directly on the pivot table to generate the bar chart. We first import the `matplotlib.pyplot` module to support Chinese display by modifying the parameters of the drawing.

````Python
import matplotlib.pyplot as plt

plt.rcParams['font.sans-serif'] = 'FZJKai-Z03S'
````

> **Description**: The above `FZJKai-Z03S` is the name of a Chinese-supporting font that has been installed on my computer. The name of the font can be viewed by viewing the name in the `.matplotlib` folder in the user's home directory. fontlist-v330.json` file, and this file will be generated after executing the above command.

Generate vector graphics using the magic command configuration.

````Python
%config InlineBackend.figure_format = 'svg'
````

Plot a histogram of Total Sales per Sales Territory.

````Python
temp = pd.pivot_table(df, index='Sales Area', values='Sales', aggfunc='sum')
temp.plot(figsize=(8, 4), kind='bar')
plt.xticks(rotation=0)
plt.show()
````

> **Description**: The 3rd line of code above will rotate the text on the horizontal axis scale to 0 degrees, and the 4th line of code will display the image.

output:

<img src="https://gitee.com/jackfrued/mypic/raw/master/20211106195040.png" style="zoom:50%">

If you want to draw a pie chart, you can modify the `kind` parameter of the `plot` method to `pie`, and then use the parameters of the custom pie chart to customize the chart, the code is as follows.

````Python
temp.sort_values(by='Sales', ascending=False).plot(
    figsize=(6, 6), kind='pie', y='sales',
    autopct='%.2f%%', pctdistance=0.8,
    wedgeprops=dict(linewidth=1, width=0.35)
)
plt.legend(loc='center')
plt.show()
````

output:

<img src="https://gitee.com/jackfrued/mypic/raw/master/20211106201550.png" style="zoom:50%">